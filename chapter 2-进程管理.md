# 操作系统王道考研复习——第二章（进程管理）


<!-- TOC -->

- [1. 程序执行](#1-程序执行)
  - [1.1. 程序顺序执行的特征](#11-程序顺序执行的特征)
  - [1.2. 程序并行执行的特征](#12-程序并行执行的特征)
- [2. 进程与线程](#2-进程与线程)
  - [2.1. 进程的概念和特征](#21-进程的概念和特征)
    - [2.1.1. 程序和进程的区别：](#211-程序和进程的区别)
    - [2.1.2. 进程的组成——PCB、程序段、数据段](#212-进程的组成pcb程序段数据段)
    - [2.1.3. 进程的特征](#213-进程的特征)
  - [2.2. 进程的状态与转换](#22-进程的状态与转换)
    - [2.2.1. 进程的三种基本状态](#221-进程的三种基本状态)
    - [2.2.2. 创建状态和终止状态](#222-创建状态和终止状态)
    - [2.2.3. 挂起操作和进程状态的转换](#223-挂起操作和进程状态的转换)
    - [2.2.4. 进程管理中的数据结构](#224-进程管理中的数据结构)
    - [2.2.5. 进程的组织方式](#225-进程的组织方式)
  - [2.3. 进程控制](#23-进程控制)
    - [2.3.1. 进程的创建](#231-进程的创建)
    - [2.3.2. 进程的终止](#232-进程的终止)
    - [2.3.3. 进程的阻塞和唤醒](#233-进程的阻塞和唤醒)
    - [2.3.4. 进程切换](#234-进程切换)
  - [2.4. 进程的组织](#24-进程的组织)
  - [2.5. 进程的通信](#25-进程的通信)
    - [2.5.1. 共享存储](#251-共享存储)
    - [2.5.2. 消息传递（最广泛的使用方式）](#252-消息传递最广泛的使用方式)
    - [2.5.3. 管道通信](#253-管道通信)
  - [2.6. 线程概念和多线程模型](#26-线程概念和多线程模型)
    - [2.6.1. 线程的引入](#261-线程的引入)
    - [2.6.2. 线程的基本概念](#262-线程的基本概念)
    - [2.6.3. 线程与进程的比较](#263-线程与进程的比较)
    - [2.6.4. 线程的属性](#264-线程的属性)
    - [2.6.5. 线程的实现方式](#265-线程的实现方式)
    - [2.6.6. 多线程模型](#266-多线程模型)
  - [2.7. 线程的状态与转换](#27-线程的状态与转换)
  - [2.8. 线程的组织与控制](#28-线程的组织与控制)
  - [2.9. 补充](#29-补充)
- [3. 处理机调度](#3-处理机调度)
  - [3.1. 调度的概念](#31-调度的概念)
    - [3.1.1. 高级调度（作业调度）](#311-高级调度作业调度)
    - [3.1.2. 低级调度（进程调度/处理机调度）](#312-低级调度进程调度处理机调度)
    - [3.1.3. 中级调度（内存调度）](#313-中级调度内存调度)
    - [3.1.4. 进程的挂起态与七状态模型](#314-进程的挂起态与七状态模型)
    - [3.1.5. 三层调度的联系和对比](#315-三层调度的联系和对比)
  - [3.2. 调度的时机、切换与过程](#32-调度的时机切换与过程)
    - [3.2.1. 进程调度的时机](#321-进程调度的时机)
      - [3.2.1.1. 需要进行进程调度与切换的情况](#3211-需要进行进程调度与切换的情况)
      - [3.2.1.2. 不能运行进程调度与切换的情况](#3212-不能运行进程调度与切换的情况)
      - [3.2.1.3. 补充](#3213-补充)
    - [3.2.2. 进程切换](#322-进程切换)
  - [3.3. 进程调度方式](#33-进程调度方式)
    - [3.3.1. 非剥夺调度方法](#331-非剥夺调度方法)
    - [3.3.2. 剥夺调度方法](#332-剥夺调度方法)
  - [3.4. 调度器/调度程序](#34-调度器调度程序)
  - [3.5. 闲逛进程](#35-闲逛进程)
  - [3.6. 调度的基本准则](#36-调度的基本准则)
    - [3.6.1. CPU利用率](#361-cpu利用率)
    - [3.6.2. 系统吞吐量](#362-系统吞吐量)
    - [3.6.3. 周转时间](#363-周转时间)
    - [3.6.4. 带权周转时间](#364-带权周转时间)
    - [3.6.5. 等待时间](#365-等待时间)
    - [3.6.6. 响应时间](#366-响应时间)
  - [3.7. 典型的调度算法](#37-典型的调度算法)
    - [3.7.1. 作业的概念](#371-作业的概念)
    - [3.7.2. 先来先服务（FCFS, First Come First Serve）](#372-先来先服务fcfs-first-come-first-serve)
    - [3.7.3. 短作业优先（SJF, Shortest Job First）](#373-短作业优先sjf-shortest-job-first)
    - [3.7.4. 高响应比优先（HRRN, Highest Response Ratio Next）](#374-高响应比优先hrrn-highest-response-ratio-next)
    - [3.7.5. 时间片轮转（RR, Round-Robin）](#375-时间片轮转rr-round-robin)
    - [3.7.6. 优先级调度算法](#376-优先级调度算法)
    - [3.7.7. 多级反馈队列调度算法](#377-多级反馈队列调度算法)
    - [3.7.8. 多级队列调度算法](#378-多级队列调度算法)
  - [3.8. 补充](#38-补充)
- [4. 进程同步](#4-进程同步)
  - [4.1. 进程同步的基本概念](#41-进程同步的基本概念)
    - [4.1.1. 进程同步](#411-进程同步)
    - [4.1.2. 进程互斥](#412-进程互斥)
    - [4.1.3. 临界资源](#413-临界资源)
    - [4.1.4. 同步机制应遵循的规则](#414-同步机制应遵循的规则)
  - [4.2. 实现临界区互斥的基本方法](#42-实现临界区互斥的基本方法)
    - [4.2.1. 软件实现方法](#421-软件实现方法)
      - [4.2.1.1. 单标志法](#4211-单标志法)
      - [4.2.1.2. 双标志先检查法](#4212-双标志先检查法)
      - [4.2.1.3. 双标志后检查法](#4213-双标志后检查法)
      - [4.2.1.4. Peterson算法](#4214-peterson算法)
    - [4.2.2. 硬件实现方法](#422-硬件实现方法)
      - [4.2.2.1. 中断屏蔽方法](#4221-中断屏蔽方法)
      - [4.2.2.2. TestAndSet指令](#4222-testandset指令)
      - [4.2.2.3. Swap指令](#4223-swap指令)
  - [4.3. 互斥锁](#43-互斥锁)
  - [4.4. 信号量](#44-信号量)
    - [4.4.1. 整型信号量](#441-整型信号量)
    - [4.4.2. 记录型信号量](#442-记录型信号量)
    - [4.4.3. 利用信号量实现进程互斥](#443-利用信号量实现进程互斥)
    - [4.4.4. 利用信号量实现进程同步](#444-利用信号量实现进程同步)
    - [4.4.5. 利用信号量实现前驱关系](#445-利用信号量实现前驱关系)
  - [4.5. 管程](#45-管程)
    - [4.5.1. 管程的定义](#451-管程的定义)
    - [4.5.2. 条件变量](#452-条件变量)
  - [4.6. 经典同步问题](#46-经典同步问题)
    - [4.6.1. 生产者-消费者问题](#461-生产者-消费者问题)
    - [4.6.2. 多生产者-多消费者](#462-多生产者-多消费者)
    - [4.6.3. 吸烟者问题](#463-吸烟者问题)
    - [4.6.4. 读者-写者问题](#464-读者-写者问题)
    - [4.6.5. 哲学家进餐问题](#465-哲学家进餐问题)
  - [4.7. 补充](#47-补充)
- [5. 死锁](#5-死锁)
  - [5.1. 死锁的概念](#51-死锁的概念)
    - [5.1.1. 资源问题](#511-资源问题)
      - [5.1.1.1. 可重用性资源](#5111-可重用性资源)
      - [5.1.1.2. 可消耗性资源](#5112-可消耗性资源)
      - [5.1.1.3. 可抢占性资源](#5113-可抢占性资源)
      - [5.1.1.4. 不可抢占性资源](#5114-不可抢占性资源)
    - [5.1.2. 死锁的定义](#512-死锁的定义)
    - [5.1.3. 死锁、饥饿、死循环的区别](#513-死锁饥饿死循环的区别)
    - [5.1.4. 死锁产生的原因](#514-死锁产生的原因)
      - [5.1.4.1. 系统资源的竞争](#5141-系统资源的竞争)
      - [5.1.4.2. 进程推进顺序非法](#5142-进程推进顺序非法)
      - [5.1.4.3. 信号量使用不当](#5143-信号量使用不当)
      - [5.1.4.4. 死锁产生的必要条件](#5144-死锁产生的必要条件)
  - [5.2. 死锁的处理策略](#52-死锁的处理策略)
  - [5.3. 死锁预防](#53-死锁预防)
    - [5.3.1. 破坏互斥条件](#531-破坏互斥条件)
    - [5.3.2. 破坏不剥夺条件](#532-破坏不剥夺条件)
    - [5.3.3. 破坏请求和保持条件](#533-破坏请求和保持条件)
    - [5.3.4. 破坏循环等待条件](#534-破坏循环等待条件)
  - [5.4. 死锁避免](#54-死锁避免)
    - [5.4.1. 系统安全状态](#541-系统安全状态)
    - [5.4.2. 银行家算法](#542-银行家算法)
      - [5.4.2.1. 银行家算法的数据结构](#5421-银行家算法的数据结构)
      - [5.4.2.2. 银行家算法的描述](#5422-银行家算法的描述)
      - [5.4.2.3. 安全性算法](#5423-安全性算法)
  - [5.5. 死锁检测和解除](#55-死锁检测和解除)
    - [5.5.1. 死锁检测](#551-死锁检测)
    - [5.5.2. 死锁解除](#552-死锁解除)
  - [5.6. 补充](#56-补充)

<!-- /TOC -->

## 1. 程序执行


### 1.1. 程序顺序执行的特征

+ **顺序性**：指处理机严格地按照程序所规定的顺序执行，即每一操作必须在下一个操作开始之前结束。
+ **封闭性**：即程序运行时独占全机资源，资源的状态（除初始状态外）只有本程序才能改变它，程序一旦开始执行，其执行结果不受外界因素影响。
+ **可再现性**：指只要程序执行时的环境和初始条件相同，当程序重复执行时，不论它是从头到尾不停顿地执行，还是“走走停停”地执行，都可获得相同的结果。


### 1.2. 程序并行执行的特征

+ **间断性**：程序在并发执行时，由于它们共享系统资源，以及为完成同一项任务而相互合作，致使在这些并发执行的程序之间形成了相互制约的关系。
+ **失去封闭性**：当系统中存在着多个可以并发执行的程序时，系统中的各种资源将为它们所共享，致使其中任一程序在运行时，其他环境都必然会受到其他程序的影响。
+ **不可再现性**：程序在并发执行时，由于失去了封闭性，也将导致其又失去可再现性。


程序在并发执行时，由于失去了封闭性，其计算结果必将与并发程序的执行速度有关，从而使程序的执行失去了可再现性。换言之，程序经过多次执行后，虽然它们执行时的环境和初始条件相同，但得到的结果却各不相同。

## 2. 进程与线程


### 2.1. 进程的概念和特征


在多道程序环境下，程序的执行属于并发执行，此时它们将失去其封闭性，并具有间断性，以及其运行结果不可再现性的特征，所以，通常的程序是不能参与并发执行的。为了能使程序并发执行，并对并发执行的程序加以描述和控制，引入了“进程”的概念。引入进程的目的是为了使其进程实体能和其他进程实体并发执行，实现操作系统的并发性和共享性（最基本的两个特征）。

进程是一个具有独立功能的程序关于某个数据集合的一次运行活动。它可以申请和拥有系统资源，是一个动态的概念，是一个活动的实体。它不只是程序的代码本身，还包括当前的活动，通过程序计数器的值和处理寄存器的内容来表示。

#### 2.1.1. 程序和进程的区别：

-   **程序**：是静态的，就是个存放在磁盘里的可执行文件。 

-   **进程**：是动态的，是程序的一次执行过程。 同一个程序多次执行会对应多个进程。

#### 2.1.2. 进程的组成——PCB、程序段、数据段

-   为了使参与并发执行的每个程序（含数据）都能独立地运行，在操作系统中必须为之配置一个专门的数据结构，称为**进程控制块（PCB）**。

    -   当进程被创建时，操作系统会为该进程分配一个唯一的、不重复的“身份证号”—— **PID（Process ID，进程ID）**。

    -   操作系统区分各个进程就是通过PID以及进程所属用户ID（UID）来区分的。所以操作系统要记录PID、UID，还要记录给进程分配了哪些资源（如：分配了多少内存、正在使用哪些I/O设备、正在使用哪些文件），还要记录进程的运行情况（如：CPU使用时间、磁盘使用情况、网络流量使用情况等）。这些信息都被保存在PCB中。

    -   操作系统需要对各个并发运行的进程进行管理，但凡管理时所需要的信息，都会被放在PCB中。

    -   操作系统就是利用PCB来描述进程的基本情况和活动过程，进而控制和管理进程。

    -   PCB是进程存在的唯一标志。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201407662.png" alt=".*?" style="zoom: 80%;" />

-   由程序段、相关的数据段和PCB三部分便构成了进程实体（又称进程映像）。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201417387.png" alt="image-20230720141741104" style="zoom: 60%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201418481.png" alt="image-20230720141826390" style="zoom: 67%;" />


由上可知，PCB是给操作系统用的，程序段和数据段才是给进程自己用的。所谓创建进程，实质上是创建进程映像中的PCB，而撤销进程，实质上是撤销进程的PCB。注意：进程映像是静态的，进程则是动态的。

从不同角度，进程可以有不同的定义，比较典型的定义有：


+ ①进程是程序的一次执行过程。
+ ②进程是一个程序及其数据在处理机上顺序执行时所发生的活动。
+ ③进程是具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。


引入进程实体后，我们可以把传统操作系统中的进程定义为：“进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。”

要注意这里说的系统资源是指处理机、存储器和其他设备服务于某个进程的“时间”，例如把处理机资源理解为处理机的时间片才是准确的。因为进程是这些资源分配和调度的独立单位，即“时间片”分配的独立单位，这就决定了进程一定是一个动态的、过程性的概念。

#### 2.1.3. 进程的特征


进程是由多道程序的并发执行而引出的，和程序是两个截然不同的概念。它拥有以下特征：


+ **动态性**：进程是程序的一次执行，它有着创建、活动、暂停、终止等过程，具有一定的生命周期，是动态地产生、变化和消亡的。动态性是进程最基本的特征。
+ **并发性**：指多个进程实体同时存于内存中，能在一段时间内运行。并发性是进程的重要特征，同时也是操作系统的重要特征。引入进程的目的就是是程序能与其他进程的程序并发执行，以提高资源利用率。
+ **独立性**：指进程实体是一个能独立运行、独立获得资源和独立接受调度的基本单位。凡未建立PCB的程序，都不能作为一个独立的单位参与运行。
+ **异步性**：由于进程的相互制约，使得进程具有执行的间断性，即进程按各自独立的、不可预知的速度向前推进。异步性会导致执行结果的不可再现性，所以在操作系统中必须配置相应的*进程同步机制*。
+ **结构性**：每个进程都配置一个PCB对其进行描述。


### 2.2. 进程的状态与转换


#### 2.2.1. 进程的三种基本状态


由于多个进程在并发执行时共享系统资源，致使它们在运行过程中呈现间断性的运行规律，所以进程在其生命周期内可能具有多种状态。一般而言，每个进程至少应处于以下三种基本状态之一：


+ **就绪态**。进程获得了除处理机外的一切所需资源，一旦得到处理机，便可立即运行。系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。（其他资源✅ CPU❌）
+ **执行态**。进程正在处理机上运行。在单处理机环境下，每个时刻最多只有一个进程处于运行态。而在多处理机系统中，则有多个进程处于执行状态。（其他资源✅ CPU✅）
+ **阻塞态**。又称等待态或封锁态。指正在执行的进程由于发生某事件（如I/O请求、申请缓冲区失败等）暂时无法继续执行时的状态，亦即进程的执行受到阻塞。此时引起进程调度，OS把处理机分配给另一个就绪进程，而让受阻进程处于暂停状态，这种暂停状态称为阻塞态。通常系统将处于阻塞态的进程也排成一个队列，称该队列为阻塞队列。实际上，在较大的系统中，为了减少队列操作的开销，提高系统效率，根据阻塞原因的不同，会设置多个阻塞队列。（其他资源❌ CPU❌）


**注意**：区别就绪态和阻塞态。就绪态是指进程仅缺少处理机，只要获得处理机资源就立即运行；而阻塞态是指进程需要其他资源（除了处理机）或等待某一事件。之所以把处理机和其他资源划分开，是因为在分时系统的时间片轮转机制中，每个进程分到的时间片是若干毫秒。也就是说，进程得到处理机的时间很短且非常频繁，进程在运行过程中实际上是频繁地转换到就绪态的；而其他资源（如外设）的使用和分配或某一事件的发生（如I/O操作的完成）对应的时间相对来说很长，进程转换到等待态的次数也相对较少。

#### 2.2.2. 创建状态和终止状态


为了满足进程控制块（PCB）对数据及操作的完整性要求以及增强管理的灵活性，通常在系统中又引入了两种常见的状态。


+ **创建态**。进程正在被创建，尚未转到就绪态。创建进程通常需要多个步骤：首先申请一个空白的PCB，并向PCB中填写一些控制和管理进程的信息；然后又系统为该进程分配运行时所必需的资源；最后把该进程转入就绪态。
+ **结束态**。进程正从系统中消失，可能是进程正常结束或其他原因中断退出运行。进程需要结束运行时，系统首先必须将该进程置为结束态，然后进一步处理资源释放和回收等。


进程PCB中，会有一个变量 state 来表示进程的当前状态。如：1表示创建态、2表示就绪态、3表示运行态…为了对同一个状态下的各个进程进行统一的管理，操作系统会将各个进程的PCB组织起来。

进程五种状态的转换如下图： 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201421228.png" alt=".*?" style="zoom: 120%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201422911.png" alt="image-20230720142211779" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201422301.png" alt="image-20230720142247204" style="zoom: 80%;" />

 进程PCB中，会有一个变量 state 来表示进程的当前状态。如：1表示创建态、2表示就绪态、3表示运行态…

为了对同一个状态下的各个进程进行统一的管理，操作系统会将各个进程的PCB组织起来。

#### 2.2.3. 挂起操作和进程状态的转换


在许多系统中，进程除了就绪、执行和阻塞三种最基本的状态外，为了系统和用户观察和分析进程的需要，还引入了一个对进程的重要操作——挂起操作。当该操作作用于某个进程时，该进程将被挂起，意味着此时该进程处于静止状态。如果进程正在执行，它将暂停执行。若原本处于就绪状态，则该进程此时暂不接受调度。与挂起操作对应的操作是激活操作。


+ 正在执行的进程挂起后，暂停执行。
+ 就绪状态的进程挂起后不接受调度。
+ W阻塞进程挂起后不能直接转换为就绪（需先激活）。


挂起操作的引入是基于系统和用户的如下需要：


+ ①终端用户的需要。当终端用户在自己的程序运行期间发现有可疑问题，希望暂停自己的程序的运行，使之停止下来，以便用户研究其执行情况或对程序进行修改。
+ ②父进程请求。有时父进程希望挂起自己的某个子进程，以便考查和修改该子进程，或者协调各子进程间的活动。
+ ③负荷调节的需要。当实时系统中的工作负荷较重，已可能影响到对实时任务的控制时，可由系统把一些不重要的进程挂起，以保证系统能正常运行。
+ ④操作系统的需要。操作系统有时希望挂起某些进程，以便检查运行中的资源使用情况或进行记账。

**挂起和阻塞态的区别**： 

-   **挂起**：由系统或程序发出，移至辅存中去。（不释放CPU，可能释放内存，移到外存去） 
-   **阻塞态**：在抢占资源中得不到资源，被动的挂起在内存，等待某种资源或信号量将它唤醒。（释放CPU，不释放内存）

加入挂起和阻塞态后的进程状态图： 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201422480.png" alt=".*?" style="zoom: 120%;" />


 其中，创建→活动就绪：在当前系统的性能和内存的容量均允许的情况下，完成对进程创建的必要操作后，相应的系统进程将进程的状态转换为活动就绪状态。

创建→静止就绪：考虑到系统当前资源状况和性能的要求，不分配给新建进程所需资源，主要是内存，相应的系统将进程状态转为静止就绪状态，被安置在外存，不参与调度，此时进程创建工作尚未完成。

#### 2.2.4. 进程管理中的数据结构


在计算机系统中，对于每个资源和每个进程都设置了一个数据结构，用于表征某实体，我们称之为资源信息表或进程信息表，其中包含了资源或进程的标识、描述、状态等信息以及一批指针。OS管理的这些数据结构一般分为以下四类：内存表、设备表、文件表和用于进程管理的进程表，通常进程表又被称为进程控制块PCB。

PCB作为进程实体的一部分，记录了操作系统所需的，用于描述进程的当前情况以及管理进程运行的全部信息，是操作系统中最重要的记录型数据结构。它使一个在多道程序环境下不能独立运行的程序（含数据）成为一个能独立运行的基本单位，一个能与其他进程并发执行的进程。

**PCB的具体作用**：


+ ①作为独立运行基本单位的标志。PCB已成为进程存在于系统中的唯一标志。
+ ②能实现间断性运行方式。在多道程序环境下，程序是采用停停走走间断性的运行方式运行的。当进程因阻塞而暂停运行时，它必须保留自己运行时的CPU现场信息，再次被调度运行时，还需要恢复其CPU现场信息。在有了PCB后，系统就可将CPU现场信息保存在被中断进程的PCB中，供该进程再次被调度执行时恢复CPU现场时使用。
+ ③提供进程管理所需信息。
+ ④提供进程调度所需信息。
+ ⑤实现了其他进程的同步通信。


**PCB中的信息**：


+ ①进程标识符。进程标识符用于唯一地标识一个进程。其中包括外部标识符（创建者提供）和内部标识符（OS设置）。
+ ②处理机状态。也称为处理机的上下文。主要由处理机中各种寄存器中的内容组成，包括通用寄存器、指令计数器、程序状态字PSW、用户栈指针等。
+ ③进程调度信息。包括进程状态、进程优先级、事件和进程调度所需的其他信息。
+ ④进程控制信息。包括程序和数据的地址、进程同步和通信机制、资源清单和链接指针。


#### 2.2.5. 进程的组织方式

+  **线性方式**。即将系统中所有的PCB都组织在一张线性表中，将该表的首地址存放在内存的一个专用区域中。该方法实现简单、开销小，但每次查找时的需要扫描整张表，因此适合数目不多的系统。 


![.*?](https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201423054.png)

+  **链接方式**。即把具有相同状态进程的PCB分别通过PCB中的链接字链接成一个队列。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201423155.png" alt=".*?" style="zoom:80%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201424542.png" alt=".*?" style="zoom:80%;" />

+  **索引方式**。即系统根据所有进程状态的不同，建立几张索引表。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201424277.png" alt="image-20230720142454162" style="zoom: 67%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201425796.png" alt=".*?" style="zoom:80%;" />


### 2.3. 进程控制


进程控制的主要功能是对系统中的所有进程实施有效的管理，它具有创建新进程、撤销已有进程、实现进程状态转换等功能。在操作系统中，一般把进程控制用的程序段称为**原语**，用原语来实现进程控制。原语的特点是执行期间不允许中断，它是一个不可分割的基本单位。

简化理解：进程控制就是要实现进程状态转换。

>   原语的执行具有原子性，即执行过程只能一气呵成，期间不允许被中断。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201425705.png" alt="image-20230720142552607" style="zoom: 67%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201426208.png" alt=".*?" style="zoom: 50%;" />

**可以用“关中断指令”和“开中断指令”这两个特权指令实现原子性。** 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201428658.png" alt="image-20230720142859591" style="zoom:67%;" />

-   正常情况：CPU每执行完一条指令都会例行检查是否有中断信号需要处理，如果有，则暂停运行当前这段程序，转而执行相应的中断处理程序。

-   CPU执行了关中断指令之后，就不再例行检查中断信号，直到执行开中断指令之后才会恢复检查，才会去执行关中断期间的外部中断程序。这样，关中断、开中断之间的这些指令序列就是不可被中断的，这就实现了“原子性”。

**以下都是进程控制相关的原语**：

#### 2.3.1. 进程的创建


允许一个进程创建另一个进程，此时创建者称为父进程，被创建的进程称为子进程。子进程可以继承父进程所拥有的资源。当子进程被撤销时，应将其从父进程那里获得的资源归还给父进程。此外，在撤销父进程时，必须同时撤销其所有的子进程。进程的创建以及引起进程创建的事件如下图所示： 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201429159.png" alt="image-20230530213719970" style="zoom: 67%;" />


 进程创建完成后会进入就绪队列。 设备分配是通过在系统中设置相应的数据结构实现的，不需要创建进程，这是操作系统中I/O核心子系统的内容。

#### 2.3.2. 进程的终止

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201430097.png" alt="image-20230720143014007" style="zoom: 67%;" />


 注意是，先对其所占有的资源执行回收操作，然后再撤销PCB。

#### 2.3.3. 进程的阻塞和唤醒

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201430064.png" alt="image-20230530213905432" style="zoom:67%;" />


 进程阻塞是进程自身的一种主动行为（挂起是被动的），也因此只有处于核心态的进程（拥有CPU），才可能将其转为阻塞态。阻塞原语（Block原语）和唤醒原语（Wakeup原语）是一对作用恰好相反的原语，必须成对使用。

#### 2.3.4. 进程切换


对于通常的进程而言，其创建、撤销及要求由系统设备完成的I/O操作，都是利用系统调用而进入内核，再由内核中的相应处理程序予以完成的。进程切换同样是在内核的支持下实现的，因此可以说，任何进程都是在操作系统内核的支持下运行的，是与内核紧密相关的。进程切换是指处理机从一个进程的运行转到另一个进程上运行。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302140709.png" alt="image-20230530214044629" style="zoom:67%;" />


 注意，进程切换与处理机模式切换是不同的。处理机模式切换时，处理机逻辑上可能还在同一进程中运行。若进程因中断或异常进入核心态运行，执行完后又回到用户态刚被中断的程序运行，则操作系统只需恢复进程进入内核时所保存的CPU现场，而无须改变当前进程的环境信息。但若要切换进程，当前运行进程改变了，则当前进程的环境信息也需要改变。

**运行环境信息称为进程的上下文；处理机状态信息称为处理机的上下文。**



无论哪个进程控制原语，要做的无非**三类事情**：


+ ①更新PCB中的信息（修改进程状态，保存/恢复运行环境）
+ ②将PCB插入合适的队列
+ ③分配/回收资源

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302146239.png" alt="image-20230530214638175" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302144337.png" alt="image-20230530214442262" style="zoom:67%;" />


### 2.4. 进程的组织


进程是一个独立的运行单位，也是操作系统进行资源分配和调度的基本单位。它由以下三部分组成，其中最核心的是进程控制块（PCB）。


+  **进程控制块** 进程创建时，操作系统为它新建一个PCB，该结构之后常驻内存，任意时刻都可以存取，并在进程结束时删除。PCB是进程实体的一部分，也是进程存在的唯一标志。 进程执行时，系统通过其PCB了解进程的现行状态信息，以便对其进行控制和管理；进程结束时，系统收回其PCB，该进程随之消亡。操作系统通过PCB表来管理和控制进程。 在进程的整个生命期中，系统总是通过PCB对进程进行控制的，亦即系统唯有通过进程的PCB才能感知到该进程的存在。 
+  **程序段** 程序段就是能被进程调度程序调度到CPU执行的程序代码段。注意：程序可被多个进程共享，即多个进程可以运行同一个程序。 
+  **数据段** 一个进程的数据段，可以是进程对应的程序加工处理的原始数据，也可以是程序执行时产生的中间或最终结果。 


### 2.5. 进程的通信


进程通信是指进程之间的信息交换。进程通信需要操作系统支持，因为进程是分配系统资源的单位（包括内存地址空间），因此各进程拥有的内存地址空间相互独立。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302147036.png" alt="image-20230530214720992" style="zoom: 67%;" />


 为了保证安全，一个进程不能直接访问另一个进程的地址空间。

PV操作是低级通信方式，高级通信方式是指以较高的效率传输大量数据的通信方式。高级通信方式方法主要有以下三类。

#### 2.5.1. 共享存储


在通信的进程之间存在一块可直接访问的共享空间，通过对这片共享空间进行写/读操作实现进程之间的信息交换。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302150710.png" alt="image-20230530215016622" style="zoom: 67%;" />


 注：通过“增加页表项/段表项”即可将同一片共享内存区映射到各个进程的地址空间中（第三章内容）。用户进程空间一般都是独立的，进程运行期间一般不能访问其他进程的空间，要想让两个用户进程共享空间，必须通过特殊的系统调用实现，而进程内的现场是自然共享进程空间的。

为避免出错，各个进程对共享空间的访问应该是互斥的。各个进程可使用操作系统内核提供的同步互斥工具（如P、V操作）。操作系统只负责为通信进程提供可共享使用的存储空间和同步互斥工具，而数据交换则由用户自己安排读/写指令完成。


+  **基于数据结构的共享** 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302151425.png" alt="image-20230530215123341" style="zoom:67%;" />


 比如共享空间里只能放一个长度为10的数组。这种共享方式仅适用于传递相对少量的数据，速度慢、限制多，是一种**低级通信**方式。 
+  **基于存储区的共享** 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302152951.png" alt="image-20230530215238767" style="zoom: 50%;" />


 操作系统在内存中划出一块共享存储区，数据的形式、存放位置都由通信进程控制，而不是操作系统。这种共享方式速度很快，是一种**高级通信**方式。 


#### 2.5.2. 消息传递（最广泛的使用方式）


进程间的数据交换以格式化的消息（Message）为单位（不同环境下，消息格式不同）。进程通过操作系统提供的“发送消息/接收消息”两个原语进行数据交换。若通信的进程之间不存在可直接访问的共享空间，则必须利用操作系统提供的消息传递方式实现进程通信。

在计算机网络中，消息又称为报文；在微内核与服务器之间的通信也都是采用了消息传递机制。

**基于消息传递的通信方式属于高级通信方式**，因其实现方式的不同，可进一步分为两类： 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302153674.png" alt="image-20230530215340588" style="zoom: 67%;" />

+ **直接通信方式**（点名道姓的消息传递） 发送进程直接把消息发送给接收进程，并将它挂在接收进程的消息缓冲队列上，接收进程从消息缓冲队列中取得消息。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201431215.png" alt=".*?" style="zoom:50%;" />


 注：由于PCB是保存在操作系统内核中，所以消息队列也是在内核中。
+ **间接通信方式**（以“信箱”作为中间实体进行消息传递） 发送进程把消息发送到某个中间实体，接收进程从中间实体取得消息。这种中间实体一般称为信箱，这种通信方式又称信箱通信方式。该通信方式广泛应用于计算机网络中，相应的通信系统称为电子邮件系统。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201431621.png" alt=".*?" style="zoom: 67%;" />

#### 2.5.3. 管道通信

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201432053.png" alt=".*?" style="zoom:67%;" />

+ **大小固定**的内存缓冲区
+ 管道只能采用**半双工通信**，某一时间段内只能实现单向的传输。如果要实现双向同时通信，则需要设置两个管道。
+ 各进程要互斥地访问管道（由操作系统实现）。
+ 当管道写满时，写进程将阻塞，直到读进程将管道中的数据取走，即可唤醒写进程。
+ 当管道读空时，读进程将阻塞，直到写进程往管道中写入数据，即可唤醒读进程。
+ 管道中的数据一旦被读出，就彻底消失。因此，当多个进程读同一个管道时，可能会错乱。对此，通常有两种解决方案：
    + ①**一个管道允许多个写进程，一个读进程**（2014年408真题高教社官方答案）；
    + ②允许有多个写进程，多个读进程，但**系统会让各个读进程轮流从管道中读数据**（Linux 的方案）。

+ 向管道（共享文件）提供输入的发送进程（即写进程），以字节流形式将大量的数据送入（写）管道；而接收管道输出的接收进程（即读进程）则从管道中接收（读）数据。为了协调双方的通信，管道机制必须提供三方面的协调能力：互斥、同步、确定对方的存在。
+ 写进程往管道写数据，即便管道没被写满，只要管道没空，读进程就可以从管道读数据。读进程从管道读数据，即便管道没被读空，只要管道没满，写进程就可以往管道写数据。
+ 从管道读取数据是一次性操作，数据一旦被读取，它就从管道中被抛弃，释放空间以便写更多的数据，管道只能采用半双工通信，即某一时刻只能单向传输，要实现父子进程双方互动通信，需要定义两个管道。
+ 管道的底层数据结构是一个**循环队列**。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302204832.png" alt="image-20230530220428697" style="zoom: 50%;" />


### 2.6. 线程概念和多线程模型


#### 2.6.1. 线程的引入


还没引入进程之前，系统中各个程序只能串行执行。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201433806.png" alt=".*?" style="zoom: 50%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201433255.png" alt=".*?" style="zoom:50%;" />


 如果说，在OS中引入进程的目的是为了使多个程序能并发执行，以提高资源利用率和系统吞吐量，那么，在OS中引入线程，则是为了减少程序在并发执行时所付出的时空开销，使OS具有更好的并发性，增加了并发度。

#### 2.6.2. 线程的基本概念

-   **线程**最直接的理解就是“轻量级进程”（LWP），它是一个**基本的CPU执行单元**，也是**程序执行流的最小单元**，由线程ID、程序计数器、寄存器集合和堆栈组成。
-   线程是进程中的一个实体，是**被系统独立调度和分派的基本单位**，线程自己不拥有系统资源，只拥有一点在运行中必不可少的资源，但它可与同属一个进程的其他线程共享进程所拥有的全部资源。

一个线程可以创建和撤销另一个线程，同个进程中的多个线程之间可以并发执行。由于线程之间的相互制约，致使线程在运行中呈现出间断性。

线程也有就绪、阻塞和运行三种基本状态。

引入线程之后，不仅是进程之间可以并发，进程内的各线程之间也可以并发，从而**进一步提升了系统的并发度**，使得一个进程内也可以并发处理各种任务（如QQ视频、文字聊天、传文件等可以并发执行）。

引入线程后，**进程只作为除CPU之外的系统资源的分配单元**（如打印机、内存地址空间等都是分配给进程的）。**线程则作为处理机的分配单元。**

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201434871.png" alt=".*?" style="zoom: 67%;" />


#### 2.6.3. 线程与进程的比较

+ **调度**：
    + 在传统的OS中，进程是资源分配、调度的基本单位。
    + 引入线程后，进程是资源分配的基本单位，线程是调度的基本单位。
        + 在同一进程中，线程的切换不会引起进程切换。
        + 在不同进程中进行线程切换，如从一个进程内的线程切换到另一个进程中的线程时，会引起进程切换。

+ **拥有资源**：
    + 不论是传统操作系统回收设有线程的操作系统，进程都是拥有资源的基本单位，
    + 而线程不拥有系统资源（只有一点必不可少的资源），但线程可以访问其隶属进程的系统资源。

+ **并发性**：
    + 在传统的OS中，只有进程间并发。
    + 在引入线程后，各线程间也能并发，提升了并发度。

+ **系统开销**：
    + 传统的进程间并发时，需要切换进程的运行环境，系统开销很大。
    + 而线程间并发时，如果是同一进程内的线程切换，则不需要切换进程环境，系统开销小。
    + 引入线程后，并发所带来的系统开销减小。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302213457.png" alt="image-20230530221350380" style="zoom: 67%;" />

#### 2.6.4. 线程的属性

多线程操作系统把线程作为独立运行（或调度）的基本单位，此时的进程已不再是一个基本的可执行实体，但它仍具有与执行相关的状态。所谓进程处于“执行”状态，实际上是指该进程中的某线程正在执行。

线程的主要属性如下：


+ 线程是处理机调度的单位
+ 多CPU计算机中，各个线程可占用不同的CPU
+ 每个线程都有一个线程ID、线程控制块（TCB）
+ 线程也有就绪、阻塞、运行三种基本状态
+ 线程几乎不拥有系统资源
+ 同一进程的不同线程间共享进程的资源
+ 由于共享内存地址空间，线程没有自己独立的地址空间，同一进程中的线程间通信甚至无需系统干预，可以直接通过它们共享的存储空间进行通信
+ 同一进程中的线程切换，不会引起进程切换
+ 不同进程中的线程切换，则会引起进程切换
+ 切换同进程内的线程，系统开销很小
+ 切换进程，系统开销较大


#### 2.6.5. 线程的实现方式


线程的实现可以分为两类：用户级线程（User-Level Thread,ULT）和内核级线程（Kernel-Level Thread,KLT）。内核级线程又称内核支持的线程。（按切换时是否依赖内核进行区分）


+  **用户级线程（ULT）** 

    +  历史背景：早期的操作系统（如：早期Unix）只支持进程，不支持线程。当时的“线程”是由线程库实现的。 在用户级线程中，有关线程管理（线程的创建、撤销和切换等）的所有工作都由应用程序完成，内核意识不到线程的存在。应用程序可以通过使用线程库设计成多线程程序。
    +  在用户级线程的系统中，其调度仍是以进程为单位。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201446863.png" alt="image-20230720144615609" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201447643.png" alt="image-20230720144715536" style="zoom:67%;" />

 很多编程语言提供了强大的线程库，可以实现线程的创建、销毁、调度等功能。 

-   1）用户级线程**由应用程序通过线程库实现**，所有的**线程管理工作都由应用程序负责（包括线程切换）**。 
-   2）用户级线程中，线程切换可以在用户态下即可完成，无需操作系统干预。 
-   3）在用户看来，是有多个线程。但是**在操作系统内核看来，并意识不到线程的存在**。“用户级线程”就是“从用户视角看能看到的线程”。 
-   4）优缺点 
    -   优点：
        -   用户级线程的切换在用户空间即可完成，不需要切换到核心态，线程管理的系统开销小，效率高。
        -   用户级线程的实现与OS无关，因为对于线程管理的代码是属于用户程序的一部分，所有的应用程序都可以对之进行共享。因此，用户级线程甚至可以在不支持线程机制的操作系统平台上实现。
    -    缺点：
        -   **当一个用户级线程被阻塞后，整个进程都会被阻塞，并发度不高。**
        -   多个线程不可在多核处理机上并行运行，因为内核每次分配给一个进程的仅有一个CPU，因此，进程中仅有一个线程能执行，在该线程放弃CPU1之前，其他线程只能等待。 

+  **内核级线程（KLT，又称“内核支持的线程”）**
    +  在内核级线程中，**线程管理的所有工作由内核完成**，应用程序没有进行线程管理的代码，只有一个到内核级线程的编程接口。
    +  内核为基础及其内部的每个线程维护上下文信息，调度也在内核基于线程架构的基础上完成，调度是以线程为单位。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201448654.png" alt="image-20230720144807586" style="zoom:67%;" />

+ 1）内核级线程的管理工作由操作系统内核完成。 
+ 2）线程调度、切换等工作都由内核负责，因此内核级线程的切换必然需要在核心态下才能完成。 
+ 3）操作系统会为每个内核级线程建立相应的TCB（Thread Control Block，线程控制块），通过TCB对线程进行管理。“内核级线程”就是“从操作系统内核视角看能看到的线程”。 
+ 4）优缺点 
    + 优点：
        + 当一个线程被阻塞后，别的线程还可以继续执行，并发能力强。
        + 多线程可在多核处理机上并行执行。

    +  缺点：
        + 一个用户进程会占用多个内核级线程，线程切换由操作系统内核完成，需要切换到核心态（用户进程的线程在用户态运行，而线程调度和管理在内核实现的），因此线程管理的成本高，开销大。 



总结：不论是进程还是线程，都必须直接或间接地取得内核的支持。由于内核支持线程可以直接利用系统调用为它服务，故线程的控制相当简单；而用户级线程必须借助于某种形式的中间系统的帮助才能取得内核的服务，故在对线程的控制上要稍微复杂些。

#### 2.6.6. 多线程模型


在支持内核级线程的系统中，根据用户级线程和内核级线程的映射关系，可以划分为几种多线程模型。


+  **一对一模型** 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201451377.png" alt="image-20230720145104209" style="zoom:67%;" />

 一个用户级线程映射到一个内核级线程。每个用户进程有与用户级线程同数量的内核级线程。

>   优点：
>
>   -   当一个线程被阻塞后，别的线程还可以继续执行，并发能力强。
>   -   多线程可在多核处理机上并行执行。 
>
>   缺点：
>
>   -   一个用户进程会占用多个内核级线程，线程切换由操作系统内核完成，需要切换到核心态，因此线程管理的成本高，开销大。 

+  **多对一模型** 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201451230.png" alt="image-20230720145130149" style="zoom:67%;" />

 即多个用户级线程映射到一个内核级线程，**且一个进程只被分配一个内核级线程**。这些用户线程一般属于一个进程，运行在该进程的用户空间，对这些线程的调度和管理也是在该进程的用户空间中完成。仅当用户线程需要访问内核时，才将其映射到一个内核控制线程上，但每次只允许一个线程进行映射。 

>   优点：用户级线程的切换在用户空间即可完成，不需要切换到核心态，线程管理的系统开销小，效率高。 
>
>   缺点：当一个用户级线程被阻塞后，整个进程都会被阻塞，并发度不高。多个线程不可在多核处理机上并行运行。 

***重点重点重点： 操作系统只“看得见”内核级线程，因此只有内核级线程才是处理机分配的单位。*** 

+  **多对多模型** 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201452444.png" alt="image-20230720145213362" style="zoom:67%;" />

 n 用户及线程映射到 m 个内核级线程（n >= m）。每个用户进程对应 m 个内核级线程。 

克服了多对一模型并发度不高的缺点（一个阻塞全体阻塞），又克服了一对一模型中一个用户进程占用太多内核级线程，开销太大的缺点。

>   ★可以这么理解： 
>
>   -   用户级线程是“代码逻辑”的载体。 
>   -   内核级线程是“运行机会”的载体。 
>   -   内核级线程才是处理机分配的单位。
>
>   例如：多核CPU环境下，上面这个进程最多能被分配两个核。一段“代码逻辑”只有获得了“运行机会”才能被CPU执行。内核级线程中可以运行任意一个有映射关系的用户级线程代码，只有两个内核级线程中正在运行的代码逻辑都阻塞时，这个进程才会阻塞。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201452904.png" alt="image-20230530223427520" style="zoom: 67%;" />

### 2.7. 线程的状态与转换

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201452492.png" alt="image-20230530223854083" style="zoom:50%;" />

### 2.8. 线程的组织与控制

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201452707.png" alt="image-20230530223952586" style="zoom: 67%;" />

### 2.9. 补充

+ 每个进程包含独立的地址空间，进程各种的地址空间是私有的，只能指向自己地址空间中的程序，且只能访问自己地址空间中的数据，相互访问会导致指针的越界错误。因此，进程之间不能直接交换数据，但可利用操作系统提高的共享文件、消息传递、共享存储区等进行通信。
+ 进程与程序的根本区别是静态和动态特点。
+ 进程调度时，优先级分静态和动态两种，动态优先级是根据运行情况而随时调整的；静态优先级则是在创建进程时确定，且在进程的整个运行期间是保持不变的。
+ 在单处理器系统中，并不是任何时刻都只有一个进程处于运行态。因为在系统发生死锁时有可能进程全部都处于阻塞态或无进程任务。
+ 在任何时刻，一个进程的状态变化不一定引起另一个进程的状态变化。例如，一个进程时间片用完，可能会引起另一个就绪进程的运行。但一个进程由阻塞态转变为就绪态就不会引起其他进程的状态变化。
+ 在单处理机系统中，若同时存在10个进程，则处于就绪队列中的进程最多有9个，1个正在运行。但处于阻塞队列中的进程最多就有可能是10个。
+ 系统进程所请求的一次I/O操作完成前，进程处于阻塞态；当I/O操作完成后，就转变为就绪态。
+ 程序封闭性是指进程执行的结果只取决于进程本身，不受外界影响。也就是说，进程在执行过程中不管是不停顿地执行，还是走走停停，进程的执行速度都不会改变它的执行结果。失去封闭性后，不同速度下的执行结果不同。
+ 进程在处理机上执行时，进程之间可能是无关的，有可能是有交互性的。
+ C语言编写的程序在使用内存时一般分为三个段，它们一般时正文段（即代码和赋值数据段）、数据堆段和数据栈段。二进制代码和常量存放在正文段，动态分配的存储区在数据堆段，临时使用的变量在数据栈段。由此，可以确定全局赋值变量在正文段赋值数据段，未赋值的局部变量和实参传递在栈段，动态内存分配在堆段，常量在正文段，进程的优先级只能在PCB中。
+ 一个进程是程序在一个数据集上的一次运行过程。运行于不同的数据集，将会形成不同的进程。
+ 系统动态DLL库中的系统线程，被不同的进程所调用，它们是相同的进程。进程是暂时的，程序是永久的；进程至少由代码、数据和PCB组成，程序仅需代码和数据即可；程序代码经过多次创建可对应不同的进程，而同一个系统的进程（或线程）可以由系统调用的方法被不同的进程（或线程）多次使用。
+ 全局变量与PCB无关，它只与用户代码有关。
+ 一个计算机系统中，进程的最大数目主要受到内存大小的限制。进程创建需要占用系统内存来存放PCB的数据结构，所以一个系统能够创建的进程总数是有限的，进程的最大数目取决于系统内存的大小。
+ 在支持多线程的系统中，进程P创建的若干线程不能共享的是进程P某线程的栈指针，因为它对其他线程是透明的。
+ 整个系统只有一个键盘，而且键盘输入是人的操作，速度比较漫，完全可以使用一个线程来处理整个系统的键盘输入，无须利用多线程。
+ 不同进程拥有不同的代码段和数据段，全局变量是对同一进程而言的，在不同的进程中是不同的变量，没有任何联系，所以不能用全局变量来交换数据。
+ 引起进程从运行态转换为就绪态的事件可能是时间片用完或者是出现了比现在进程优先级更改的进程。
+ 降低进程优先级的合理时机是进程时间片用完，因为可以让其他进程被调度进入执行状态。当进程刚完成I/O操作，进入就绪队列等待被处理机调度时，为了让其尽快处理I/O结果，就应该提高优先级。当进程长期处于就绪队列时，为了不至于产生饥饿现象，也应提高优先级。
+ 多线程是指一个程序中可以定义多个线程并同时运行它们，每个线程可以执行不同的任务。多线程与多任务的区别：多任务是针对操作系统而言的，代表操作系统可以同时执行的程序个数；多线程是针对一个程序而言的，代表一个程序可以同时执行的线程个数，而每个线程可以完成不同的任务。
+ 若系统中没有运行进程，则一定没有就绪进程。因为若系统中未运行进程，则系统很快会选择一个就绪进程运行，只有就绪队列中无进程时，CPU才可能处于空闲状态。
+ 在采用优先级进程调度时，运行进程不一定是系统中优先级最高的进程。因为高优先级的进程有可能正处于等待队列中，进程调度会从就绪队列中选择一个进程占用CPU，这个被选中的进程可能优先级较低。


## 3. 处理机调度


### 3.1. 调度的概念

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201453197.png" alt=".*?" style="zoom:50%;" />


 当有一堆任务要处理，但由于资源有限，这些事情没法同时处理。这就需要确定某种规则来决定处理这些任务的顺序，这就是“调度”研究的问题。调度的实质是一种资源分配。

一个作业从提交开始直到完成，往往要经历以下三种调度：

#### 3.1.1. 高级调度（作业调度）

>   作业：一个具体的任务
>   用户向系统提交一个作业 ≈ 用户让操作系统启动一个程序（来处理一个具体的任务）

-   它的调度对象是作业。
-   其主要功能是根据某种算法，决定将外存上处于后备队列中的哪几个作业调入内存，为它们创建进程、分配必要的资源，将它们放入到就绪队列。
-   高级调度**主要用于多道批处理系统中**，而其他系统通常不配置作业调度，作业调度的执行效率较低，通常为几分钟一次。

-   对于每个作业只调入一次，调出一次。调入时候会建立PCB，调出时会撤销PCB。

#### 3.1.2. 低级调度（进程调度/处理机调度）

-   它的调度对象是进程或内核级线程。
-   按照某种策略从就绪队列中选取一个进程，将处理机分配给它。
-   **进程调度是操作系统中最基本的一种调度**，在一般的操作系统中都必须配置进程调度。
-   进程调度的**频率很高**，一般几十毫秒一次。

#### 3.1.3. 中级调度（内存调度）

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201453518.png" alt=".*?" style="zoom: 50%;" />

-   其作用是**提高内存利用率和系统吞吐量**。
-   为此，应将那些**暂时不能运行的进程调至外存等待**，把此时的进程状态称为挂起态。
-   当它们已具备运行条件且内存又稍有空闲时，由中级调度来决定把外存上那些已具备运行条件的就绪进程，再重新调入内存，并修改其状态为就绪态，挂在就绪队列上等待。
-   中级调度（内存调度）——按照某种策略决定将哪个处于挂起状态的进程重新调入内存。
-   一个进程可能会被多次调出、调入内存，因此**中级调度发生的频率要比高级调度更高**。

#### 3.1.4. 进程的挂起态与七状态模型


暂时调到外存等待的进程状态为挂起状态（挂起态，suspend）。 挂起态又可以进一步细分为就绪挂起、阻塞挂起两种状态。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302259259.png" alt="image-20230530225939163" style="zoom: 40%;" />

>   注意“挂起”和“阻塞”的区别，两种状态都是暂时不能获得CPU的服务，但**挂起态是将进程映像调到外存去了，而阻塞态下进程映像还在内存中**。 
>
>   有的操作系统会把就绪挂起、阻塞挂起分为两个挂起队列，甚至会根据阻塞原因不同再把阻塞挂起进程进一步细分为多个队列。

#### 3.1.5. 三层调度的联系和对比

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201454776.png" alt=".*?" style="zoom: 60%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302305060.png" alt="image-20230530230533964" style="zoom: 70%;" />

### 3.2. 调度的时机、切换与过程


#### 3.2.1. 进程调度的时机


进程调度（低级调度），就是按照某种算法从就绪队列中选择一个进程为其分配处理机。

##### 3.2.1.1. 需要进行进程调度与切换的情况


+ 当前运行的进程主动放弃处理机 

    + ①进程正常终止 
    + ②运行过程中发生异常而终止 
    + ③进程主动请求阻塞（如 等待I/O）

+ 当前运行的进程被动放弃处理机 

    + ①分给进程的时间片用完 
    + ②有更紧急的事需要处理（如 I/O中断） 
    + ③有更高优先级的进程进入就绪队列

##### 3.2.1.2. 不能运行进程调度与切换的情况

​		①在处理中断的过程中。中断处理过程复杂，与硬件密切相关，很难做到在中断处理过程中进行进程切换。 

​		②进程在操作系统**内核程序临界区**中。（注意：进程调度和切换程序都是操作系统内核程序）

​		③在原子操作过程中（原语）。原子操作不可中断，要一气呵成（如之前讲过的修改PCB中进程状态标志，并把PCB放到相应队列就属于原子操作）

##### 3.2.1.3. 补充

*有如下的判断题*： 


![.*?](https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201454520.png)

-   **临界资源**：一个时间段内只允许一个进程使用的资源。各进程需要***互斥地访问临界资源***。 

-   **临界区**：*访问临界资源的那段代码*。 内核程序临界区一般是用来访问某种内核数据结构的，比如进程的就绪队列（由各就绪进程的PCB组成）

当进程处于临界区时，说明进程正在占用处理机，只要不破坏临界资源的使用规则，就不会影响处理机的调度，比如访问的临界资源是慢速的外设（如打印机）。所以在访问临界区时能不能进行调度和切换还得看情况。

再通过以下两个例子，相信大家可以更加理解什么时候可以进行调度和切换： 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201457237.png" alt="image-20230720145714146" style="zoom:67%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201458497.png" alt="image-20230720145822410" style="zoom: 67%;" />


 在访问内核程序临界区期间时不能进行调度与切换；而在访问普通临界区时可以进行调度与切换。

#### 3.2.2. 进程切换

-   **进程切换**往往在调度完成后<u>立刻发生</u>，它要求保存原进程当前切换点的现场信息，恢复被调度进程的现场信息。
    -   现场切换时，操作系统内核将原进程的现场信息推入当前进程的内核堆栈来保存它们，并更新堆栈指针。
    -   内核完成从新进程的内核栈中装入新机场的现场信息、更新当前运行进程空间指针、重设PC寄存器等相关工作之后，开始运行新的进程。

-   “狭义的进程调度”与“进程切换”的区别： 
    -   狭义的进程调度指的是从就绪队列中选中一个要运行的进程。（这个进程可以是刚刚被暂停执行的进程，也可能是另一个进程，后一种情况就需要进程切换） 
    -   进程切换是指一个进程让出处理机，由另一个进程占用处理机的过程。

-   广义的进程调度包含了选择一个进程和进程切换两个步骤。 
-   进程切换的过程主要完成了： 
    -   ①对原来运行进程各种数据的保存 
    -   ②对新的进程各种数据的恢复（如：程序计数器、程序状态字、各种数据寄存器等处理机现场信息，这些信息一般保存在进程控制块） 

<u>★注意/重要结论：**进程的调度、切换是有代价的，因此如果过于频繁的进行进程调度、切换，必然会使整个系统的效率降低，使系统大部分时间都花在了进程切换上，而真正用于执行进程的时间减少。**</u>

### 3.3. 进程调度方式


所谓进程调度方式，是指当某个进程正在处理机上执行时，若有某个更为重要或紧迫的基础需要处理，即有优先权更高的进程进入就绪队列，此时应如何分配处理机。通常有以下两个进程调度方式：

#### 3.3.1. 非剥夺调度方法

-   非剥夺调度方式，又称**非抢占方式**。
    -   即，只允许进程主动放弃处理机。在运行过程中即便有更紧迫的任务到达，当前进程依然会继续使用处理机，直到该进程终止或主动要求进入阻塞态。

-   在非剥夺调度方式下，一旦把CPU分配给一个进程，该进程就会保持CPU直到终止或转换到阻塞态。

-   这种方法实现简单，系统开销小但是无法及时处理紧急任务，**适合于早期的批处理系统**，不能用于分时系统和大多数的实时系统。

#### 3.3.2. 剥夺调度方法

-   剥夺调度方式，又称抢占方式。
    -   当一个进程正在处理机上执行时，如果有一个更重要或更紧迫的进程需要使用处理机，则立即暂停正在执行的进程，**将处理机分配给更重要紧迫的那个进程**。

-   这种方法可以优先处理更紧急的进程，也可实现让各进程按时间片轮流执行的功能（通过时钟中断）。
-   适合于分时操作系统、实时操作系统。
-   采用剥夺式的调度，对提高系统吞吐率和响应效率都有明显的好处。
-   但“剥夺”不是一种任意性行为，必须遵循一定的原则，主要由优先权、短进程优先和时间片原则等。

### 3.4. 调度器/调度程序

>   <img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302334953.png" alt="image-20230530233439905" style="zoom: 67%;" />
>
>   ②、③由调度程序引起，调度程序决定：
>
>   -   让谁运行？——调度算法；
>   -   运行多长时间？——时间片大小

-   调度时机——什么事件会触发“调度程序”？
    -   **创建新进程**
    -   进程退出
    -   运行**进程阻塞**
    -   I/O中断发生（可能唤醒某些阻塞进程）

-   非抢占式调度策略，只有运行进程阻塞或退出才触发调度程序工作
-   抢占式调度策略，每个**时钟中断**或k个时钟中断会触发调度程序工作

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305302337746.png" alt="image-20230530233757673" style="zoom: 67%;" />

-   进程作为资源分配的基本单位。

### 3.5. 闲逛进程

>   闲逛进程（Idle Process）是指在操作系统中运行的一种特殊类型的进程，也被称为空闲进程或系统闲置进程。它是由操作系统创建并在系统空闲时运行的进程。
>
>   闲逛进程通常不执行任何有意义的任务，而是处于一种空闲状态，等待系统需要进行处理时提供服务。它的存在是为了确保系统的稳定性和正常运行。
>
>   闲逛进程的主要作用如下：
>
>   1.  资源管理：当系统中没有其他任务需要执行时，闲逛进程会占用处理器资源，以避免处理器空闲浪费。它可以持续占用处理器的运算能力，使得系统不会因为处理器闲置而浪费资源。
>   2.  节能和降温：闲逛进程对于节能和降温也具有一定的作用。在系统空闲时，闲逛进程可以减少处理器的工作负载，降低功耗和温度，从而节省能源并延长硬件寿命。
>   3.  系统保护：闲逛进程还有助于系统的保护和安全。通过占用处理器资源，它可以防止未经授权的程序或恶意软件利用系统的空闲时间进行攻击或干扰。
>
>   闲逛进程通常具有最低的优先级，当其他任务需要执行时，操作系统会优先调度和分配资源给这些任务。闲逛进程会进入休眠状态，直到系统再次变得空闲时才会重新启动。
>
>   总之，闲逛进程是一种特殊的系统进程，用于占用处理器资源并保持系统正常运行。它在系统空闲时发挥作用，提供资源管理、节能降温和系统保护等功能。

-   调度程序永远的备胎，没有其他就绪进程时，运行闲逛进程。
-   特性
    -   优先级最低
    -   可以是0地址指令，占一个完整的指令周期（指令周期末尾例行检查中断）
    -   能耗低

### 3.6. 调度的基本准则

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311340751.png" alt="image-20230531134045667" style="zoom:67%;" />


#### 3.6.1. CPU利用率

由于早期的CPU造价极其昂贵，因此人们会希望让CPU尽可能多地工作。 

-   **CPU利用率**：指CPU “忙碌”的时间占总时间的比例。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311328232.png" alt="image-20230531132854103" style="zoom: 67%;" />


#### 3.6.2. 系统吞吐量

对于计算机来说，希望能用尽可能少的时间处理完尽可能多的作业。 

-   **系统吞吐量**：单位时间内完成作业的数量。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311329626.png" alt="image-20230531132948576" style="zoom:67%;" />


#### 3.6.3. 周转时间

-   **周转时间**，是指从<u>作业被提交给系统开始</u>，到<u>作业完成为止</u>的这段时间间隔。 

-   它包括四个部分：
    -   作业在外存后备队列上等待作业调度（高级调度）的时间、
    -   进程在就绪队列上等待进程调度（低级调度）的时间、
    -   进程在CPU上执行的时间、
    -   进程等待I/O操作完成的时间。
-   后三项在一个作业的整个处理过程中，可能发生多次。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311332731.png" alt="image-20230531133223654" style="zoom:67%;" />

#### 3.6.4. 带权周转时间

 有的作业运行时间短，有的作业运行时间长，因此在周转时间相同的情况下，运行时间不同的作业，给用户的感觉肯定是不一样的。所以有了**带权周转时间**。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311334310.png" alt="image-20230531133453248" style="zoom:67%;" />

-   对于周转时间相同的两个作业，实际运行时间长的作业在相同时间内被服务的时间更多，带权周转时间更小，用户满意度更高。 

-   对于实际运行时间相同的两个作业，周转时间短的带权周转时间更小，用户满意度更高。
-   带权周转时间**越小越好**。

#### 3.6.5. 等待时间

-   **等待时间**，指进程/作业处于等待处理机状态时间之和，<u>等待时间越长，用户满意度越低。</u> 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311348750.png" alt="image-20230531134835659" style="zoom:67%;" />

-   对于进程来说，等待时间就是指**进程建立后等待被服务的时间之和**，在等待I/O完成的期间其实进程也是在被服务的，所以不计入等待时间。 

-   对于作业来说，不仅要考虑建立进程后的等待时间，**还要加上作业在外存后备队列中等待的时间**。

一个作业总共需要被CPU服务多久，被I/O设备服务多久一般是确定不变的，因此**调度算法其实只会影响作业/进程的等待时间**。当然，与前面指标类似，也有“**平均等待时间**”来评价整体性能。

#### 3.6.6. 响应时间

对于计算机用户来说，会希望自己的提交的请求（比如通过键盘输入了一个调试命令）尽早地开始被系统服务、回应。 

-   响应时间，指从用户**提交请求到首次产生响应**所用的时间。

### 3.7. 典型的调度算法

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311347983.png" alt="image-20230531134726909" style="zoom:67%;" />


操作系统中存在多种调度算法，有的调度算法适用于作业调度，有的调度算法适用于进程调度，有的调度算法两者都适用。下面首先介绍一下作业的概念。

#### 3.7.1. 作业的概念


在多道批处理系统中，作业是用户提交给系统的一项相对独立的工作。操作员把用户提交的作业通过相应的输入设备输入到磁盘存储器，并保存在一个后备作业队列中。再由作业调度程序将其从外存调入内存。

**作业**是一个比程序更为广泛的概念，它不仅包含了通常的程序和数据，而且还应配有一份作业说明书，系统根据该说明书来对程序的运行进行控制。在批处理系统中，是以作业为基本单位从外存调入内存的。

作业从进入系统到运行结束，通常需要经历收容、运行和完成三个阶段。相应的作业也就有“提交状态”、“后备状态”、“运行状态”和“完成状态”。

下面介绍一下调度算法：

#### 3.7.2. 先来先服务（FCFS, First Come First Serve）

FCFS调度算法是一种最简单的调度算法，它既可用于作业调度，又可用于进程调度。

在作业调度中，算法每次从后备作业队列中选择最先进入该队列的一个或几个作业，将它们调入内存，分配必要的资源，创建进程并放入就绪队列。

在进程调度中，FCFS调度算法每次从就绪队列中选择最先进入该队列的进程，将处理机分配给它，使之投入运行，直到完成或因某种原因而阻塞时才释放处理机。


+ **算法思想：** 主要从“公平”的角度考虑（类似于我们生活中排队买东 西的例子）
+ **算法规则：** 按照作业/进程到达的先后顺序进行服务，或者说它是优先考虑在系统中等待时间最长的作业。
+ **用于作业/进程调度：** 用于作业调度时，考虑的是哪个作业先到达后备队列；用于进程调度时，考虑的是哪个进程先到达就绪队列
+ **是否可抢占？** 非抢占式的算法
+ **优缺点：** 

    + 优点：公平、算法实现简单。
    + 缺点：排在长作业（进程）后面的短作业需要等待很长时间，带权周转时间很大，对短作业来说用户体验不好。
    + 即FCFS算法**对长作业有利，对短作业不利**。

+ **是否会导致饥饿（某进程/作业长期得不到服务）：** 不会



>   例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用先来先服务调度算法，计算各进程的等待时间、平均等待时间、周转时间、平均周转时间、带权周转时间、平均带权周转时间。 
>
>   <img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311359389.png" alt="image-20230531135907143" style="zoom: 40%;" />

#### 3.7.3. 短作业优先（SJF, Shortest Job First）

短作业优先（SJF）调度算法从后备队列中选择一个或者若干估计运行时间最短的作业，将它们调入内存运行；

短进程优先（SPF）调度算法从就绪队列中选择一个估计运行时间最短的进程，将处理机分配给它，使之立即执行，直到完成或发生某事件而阻塞时，才释放处理机。


+ **算法思想：** 追求最少的平均等待时间，最少的平均周转时间、最少的平均带权周转时间
+ **算法规则：** 最短的作业/进程优先得到服务（所谓“最短”，是指要求服务时间最短）
+ **用于作业/进程调度：** 即可用于作业调度，也可用于进程调度。用于进程调度时称为“短进程优先（SPF, Shortest Process First）算法”
+ **是否可抢占？** SJF和SPF是非抢占式的算法。但是也有抢占式的版本——**最短剩余时间优先算法**（**SRTN**, Shortest Remaining Time Next）
+ **优缺点：** 

    + 优点：“最短的”（这里的最短的是得看条件的）平均等待时间、平均周转时间。
    + 缺点：不公平。对短作业有利，对长作业不利。**可能产生饥饿现象。**
    + 另外，作业/进程的运行时间是由用户提供（用户估计的）的，并不一定真实，不一定能做到真正的短作业优先。

+ **是否会导致饥饿：** 会。如果源源不断地有短作业/进程到来，可能使长作业/进程长时间得不到服务，产生“饥饿”现象。**如果一直得不到服务，则称为“饿死”。**



>   例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用非抢占式的短作业优先调度算法，计算各进程的等待时间、平均等待时间、周转时间、平均周转时间、带权周转时间、平均带权周转时间。 
>
>   <img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311402947.png" alt="image-20230531140239837" style="zoom: 67%;" />

>   例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用抢占式的短作业优先调度算法，计算各进程的等待时间、平均等待时间、周转时间、平均周转时间、带权周转时间、平均带权周转时间。**（抢占式的短作业优先算法又称“最短剩余时间优先算法（SRTN）”）** 
>
>   <img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311405408.png" alt="image-20230531140553302" style="zoom:67%;" />
>
>   <img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311407839.png" alt="image-20230531140725752" style="zoom: 67%;" />

**注意几个小细节**：


+ 如果题目中未特别说明，所提到的“短作业/进程优先算法”默认是非抢占式的。
+ 很多书上都会说“SJF 调度算法的平均等待时间、平均周转时间最少”。 严格来说，这个表述是错误的，不严谨的。之前的例子表明，最短剩余时间优先算法得到的平均等待时间、平均周转时间还要更少。 

    + 应该加上一个条件“在所有进程同时可运行时，采用SJF调度算法的平均等待时间、平均周转时间最少”；
    + 或者说“在所有进程都几乎同时到达时，采用SJF调度算法的平均等待时间、平均周转时间最少”；
    +  如果不加上述前提条件，则应该“抢占式的短作业/进程优先调度算法（最短剩余时间优先, SRNT算法）的平均等待时间、平均周转时间最少”

+ 虽然严格来说，SJF的平均等待时间、平均周转时间并不一定最少，但相比于其他算法（如 FCFS），SJF依然可以获得较少的平均等待时间、平均周转时间。
+ 如果选择题中遇到“SJF 算法的平均等待时间、平均周转时间最少”的选项，那最好判断其他选项是不是有很明显的错误，如果没有更合适的选项，那也应该选择该选项。


#### 3.7.4. 高响应比优先（HRRN, Highest Response Ratio Next）

在批处理系统中，FCFS算法所考虑的只是作业的等待时间，而忽视了作业的运行时间。而SJF算法正好与之相反，只考虑作业的运行时间，而忽视了作业的等待时间。

HRRN是一个既考虑到各个作业的等待时间，也能兼顾运行时间的调度算法，因此既照顾了短作业，又不致使长作业的等待时间过长，从而改善了处理机调度的性能。


+ **算法思想：** 要综合考虑作业/进程的等待时间和要求服务的时间
+ **算法规则：** 在每次调度时先计算各个作业/进程的响应比，选择响应比最高的作业/进程为其服务。 


![.*?](https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201459452.png)

+ **用于作业/进程调度：** 即可用于作业调度，也可用于进程调度。
+ **是否可抢占？** 非抢占式的算法。因此只有当前运行的作业/进程主动放弃处理机时，才需要调度，才需要计算响应比。
+ **优缺点：** 
    + 优点：
        + 综合考虑了等待时间和运行时间（要求服务时间）；
        + 等待时间相同时，要求服务时间短的优先（SJF 的优点）；
        + 要求服务时间相同时，等待时间长的优先（FCFS 的优点）；
        + 对于长作业来说，随着等待时间越来越久，其响应比也会越来越大，从而避免了长作业饥饿的问题。

    + 缺点：每次要进行调度之前，都需要先做响应比的计算，显然会**增加系统开销**。

+ **是否会导致饥饿：** 不会



>   例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用高响应比优先调度算法，计算各进程的等待时间、平均等待时间、周转时间、平均周转时间、带权周转时间、平均带权周转时间。 
>
>   <img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311420861.png" alt="image-20230531142030747" style="zoom: 67%;" />

**小结：** 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311422285.png" alt="image-20230531142251182" style="zoom: 67%;" />

注：

-   这几种算法主要关心对用户的公平性、平均周转时间、平均等待时间等评价系统整体性能的指标，但是不关心“响应时间”，也并不区分任务的紧急程度，因此对于用户来说，交互性很糟糕。
-   因此这三种算法一般**适合用于早期的批处理系统**，当然，FCFS算法也常结合其他的算法使用，在现在也扮演着很重要的角色。

-   而适合用于**交互式系统的调度算法**将在下面介绍。

#### 3.7.5. 时间片轮转（RR, Round-Robin）


时间片轮转调度算法主要适用于**分时系统**，**更加注重“响应时间”。**


+ **算法思想：** 公平地、轮流地为各个进程服务，让每个进程在一定时间间隔内都可以得到响应。
+ **算法规则：** 按照各进程到达就绪队列的顺序，轮流让各个进程执行一个**时间片**（如 100ms）。若进程未在一个时间片内执行完，则剥夺处理机，将进程重新放到就绪队列队尾重新排队。
+ **用于作业/进程调度：** 用于进程调度（作业要先放入内存建立了相应的进程后，才能被分配处理机时间片，所以没有作业调度）。
+ **是否可抢占？** 若进程未能在时间片内运行完，将被强行剥夺处理机使用权 ，因此时间片轮转调度算法属于抢占式的算法。由时钟装置发出时钟中断来通知CPU时间片已到。
+ **优缺点：** 

    + 优点：公平；响应快，适用于**分时操作系统**；
    + 缺点：由于高频率的进程切换，因此有一定开销；不区分任务的紧急程度。
+ **是否会导致饥饿：** 不会
+ **补充：** 

    + 若选择很小的时间片，将有利于短作业，因为它能在该时间片内完成。但时间片小，意味着会频繁地执行进程调度和进程上下文的切换，这无疑会增加系统的开销。
    + 反之，若时间片选择得太长，且为使每个进程都能在一个时间片内完成，RR算法便退化为FCFS算法，无法满足短作业和交互式用户的需求。




>   例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用时间片轮转调度算法，分析时间片大小分别是2、5时的进程运行情况。 


![.*?](https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201459865.png)

>   -   时间片大小为 2 时（注：以下括号内表示当前时刻就绪队列中的进程、进程的剩余运行时间）>   

| 时刻                                   | 事件                                                         |
| -------------------------------------- | :----------------------------------------------------------- |
| 0时刻（P1(5)）                         | 0时刻只有P1到达就绪队列，让P1上处理机运行一个时间片. 2时刻（P2(4) → P1(3)） |
| 2时刻（P2(4) → P1(3)）                 | P2到达就绪队列，P1运行完一个时间片，被剥夺处理机，重新放到队尾。此时P2排在队头，因此让P2上处理机。<br />（**注意**： 2时刻，P1下处理机，同一时刻新进程P2到达，如果在题目中遇到这种情况，**默认新到达的进程先进入就绪队列**）。 |
| 4时刻（P1(3) → P3(1) → P2(2)）         | 4时刻，P3到达，先插到就绪队尾，紧接着，P2下处理机也插到队尾。 |
| 5时刻（P3(1) → P2(2) → P4(6)）         | 5时刻，P4到达插到就绪队尾（**注意**：由于P1的时间片还没用完，因此暂时不调度。另外，<u>此时P1处于运行态，并不在就绪队列中</u>）。 |
| 6时刻（P3(1) → P2(2) → P4(6) → P1(1)） | 6时刻，P1时间片用完，下处理机，重新放回就绪队尾，发生调度。  |
| 7时刻（P2(2) → P4(6) → P1(1)）         | 虽然P3的时间片没用完，但是由于P3只需运行1个单位的时间，运行完了会主动放弃处理机，因此也会发生调度。队头进程P2上处理机。 |
| 9时刻（P4(6) → P1(1)）                 | 进程P2时间片用完，并刚好运行完，发生调度，P4上处理机。       |
| 11时刻（P1(1) → P4(4)）                | P4时间片用完，重新回到就绪队列。P1上处理机。                 |
| 12时刻（P4(4)）                        | P1运行完，主动放弃处理机，此时就绪队列中只剩P4，P4上处理机。 |
| 14时刻（）                             | 就绪队列为空，因此让P4接着运行一个时间片。                   |
| 16时刻                                 | 所有进程运行结束。                                           |

>   -   时间片大小为 5时 

| 时刻                           | 事件                                                         |
| ------------------------------ | :----------------------------------------------------------- |
| 0时刻（P1(5)）                 | 只有P1到达，P1上处理机。                                     |
| 2时刻（P2(4)）                 | P2到达，但P1时间片尚未结束，因此暂不调度。                   |
| 4时刻（P2(4) → P3(1)）         | P3到达，但P1时间片尚未结束，因此暂不调度。                   |
| 5时刻（P2(4) → P3(1) → P4(6)） | P4到达，同时，P1运行结束。发生调度，P2上处理机。             |
| 9时刻（P3(1) → P4(6)）         | P2运行结束，虽然时间片没用完，但是会主动放弃处理机。发生调度。 |
| 10时刻（ P4(6) ）              | P3运行结束，虽然时间片没用完，但是会主动放弃处理机。发生调度。 |
| 15时刻（ ）                    | P4时间片用完，但就绪队列为空，因此会让P4继续执行一个时间片。 |
| 16时刻（ ）                    | P4运行完，主动放弃处理机。所有进程运行完。                   |


![.*?](https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201459862.png)

>   若按照先来先服务调度算法，则是这样： 


![.*?](https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201459144.png)

>   如果**时间片太大**，使得每个进程都可以在一个时间片内就完成，则时间片轮转调度算法**退化为先来先服务调度算法**，并且会增大进程响应时间。因此时间片不能太大。 
>
>   另一方面，进程调度、切换是有时间代价的（保存、恢复运行环境），因此如果时间片太小，会导致**进程切换过于频繁**，系统会花大量的时间来处理进程切换，从而导致实际用于进程执行的时间比。（一般来说，设计时间片时要**让切换进程的开销占比不超过1%**)


#### 3.7.6. 优先级调度算法


优先级调度算法又称优先权调度算法，它既可用于作业调度，又可用于进程调度。该算法中的优先级用于作业运行的紧迫程度。


+ **算法思想：** 随着计算机的发展，特别是实时操作系统的出现，越来越多的应用场景需要**根据任务的紧急程度**来决定处理顺序。

+ **算法规则：** 每个作业/进程有各自的优先级，调度时选择优先级最高的作业/进程。

+ **用于作业/进程调度：** 既可用于作业调度，也可用于进程调度。甚至，还会用于在之后会学习的I/O调度中。

+ **是否可抢占？** 抢占式、非抢占式都有。
    + 做题时的区别在于：
        + 非抢占式只需在进程主动放弃处理机时进行调度即可
        + 而抢占式还需在就绪队列变化时，检查是否会发生抢占。
    + 抢占式的优先级调度算法：
        + 每次调度时选择当前已到达且优先级最高的进程。
        + 当前进程主动放弃处理机时发生调度。
        + 另外，当就绪队列发生改变时也需要检查是会发生抢占。
+ **优缺点：** 
    + 优点：用优先级区分紧急程度、重要程度，适用于实时操作系统。可灵活地调整对各种作业/进程的偏好程度。
    + 缺点：若源源不断地有高优先级进程到来，则可能导致饥饿。
+ **是否会导致饥饿：** 会
+ **补充：** 
    + 就绪队列未必只有一个，可以按照不同优先级来组织。
    + 另外，也可以把优先级高的进程排在更靠近队头的位置。 
    + 根据优先级是否可以动态改变，可将优先级分为静态优先级和动态优先级两种。
        + 静态优先级：创建进程时确定，之后一直不变。 
        + **动态优先级**：创建进程时有一个初始值，之后会根据情况动态地调整优先级。
    + 如何合理地设置各类进程的优先级？ 
        通常： 
        
        + 系统进程优先级高于用户进程 
        + 前台进程优先级高于后台进程 
        + 操作系统更偏好 I/O型进程（或称 I/O繁忙型进程）【 **I/O设备和CPU可以并行工作**。如果优先让I/O繁忙型进程优先运行的话， 则越有可能让I/O设备尽早地投入工作，则资源利用率、系统吞吐量都会得到提升】 
            + 注：与I/O型进程相对的是计算型进程（或称 CPU繁忙型进程）
        
    + 如果采用的是动态优先级，什么时候应该调整？ 
    
        可以从**追求公平、提升资源利用率**等角度考虑 
    
        + 如果某进程在就绪队列中等待了很长时间，则可以适当提升其优先级。【响应比增大】
        + 如果某进程占用处理机运行了很长时间，则可适当降低其优先级 。
        + 如果发现一个进程频繁地进行I/O操作，则可适当提升其优先级



>   例题：各进程到达就绪队列的时间、需要的运行时间、进程优先数如下表所示。使用**非抢占式**的优先级调度算法，分析进程运行情况。（注：**优先数越大，优先级越高**）(这个是不同的题目不一样的，有的题目是“优先数越小，优先级越大”，要**根据不同的题目要求来做题**） 


![.*?](https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201501519.png)

>   注：以下括号内表示当前处于就绪队列的进程 

| 时刻                    | 事件                                                         |
| ----------------------- | :----------------------------------------------------------- |
| 0时刻（**P1**）         | 只有P1到达，P1上处理机。                                     |
| 7时刻（P2、**P3**、P4） | P1运行完成主动放弃处理机，其余进程都已到达，P3优先级最高，P3上处理机。 |
| 8时刻（P2、P4）         | P3完成，P2、P4优先级相同，由于P2先到达，因此P2优先上处理机。 |
| 12时刻（**P4**）        | P2完成，就绪队列只剩P4，P4上处理机。                         |
| 16时刻（）              | P4完成，所有进程都结束。                                     |

>   
>
>   例题：各进程到达就绪队列的时间、需要的运行时间、进程优先数如下表所示。使用**抢占式**的优先级调度算法，分析进程运行情况。（注：**优先数越大，优先级越高**） 


![.*?](https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201501591.png)

>   注：以下括号内表示当前处于就绪队列的进程

| 时刻                | 事件                                                         |
| ------------------- | :----------------------------------------------------------- |
| 0时刻（P1）         | 只有P1到达，P1上处理机。                                     |
| 2时刻（P2）         | P2到达就绪队列，优先级比P1更高，发生抢占。P1回到就绪队列，P2上处理机。 |
| 4时刻（P1、P3）     | P3到达，优先级比P2更高，P2回到就绪队列，P3抢占处理机。       |
| 5时刻（P1、P2、P4） | P3完成，主动释放处理机，同时，P4也到达，由于P2比P4更先进入就绪队列，因此选择P2上处理机。 |
| 7时刻（P1、P4）     | P2完成，就绪队列只剩P1、P4，P4上处理机。                     |
| 11时刻（P1）        | P4完成，P1上处理机。                                         |
| 16时刻（）          | P1完成，所有进程均完成。                                     |


#### 3.7.7. 多级反馈队列调度算法

+ **算法思想：** 对其他调度算法的折中权衡
+ **算法规则：** 
  + ①设置多级就绪队列，各级队列优先级从高到低，时间片从小到大。 
  + ②新进程到达时先进入第1级队列，按FCFS原则排队等待被分配时间片
    + 若用完时间片进程还未结束，则进程进入下一级队列队尾。
    + 如果此时已经是在最下级的队列，则重新放回该队列队尾。 

  + ③只有第 k 级队列为空时，才会为 k+1 级队头的进程分配时间片。

+ **用于作业/进程调度：** 用于进程调度
+ **是否可抢占？** 
    + **抢占式**的算法。在 k 级队列的进程运行过程中，若更上级的队列（1~k-1级）中进入了一个新进程，则由于新进程处于优先级更高的队中，因此新进程会抢占处理机，原来运行的进程放回 k 级队列队尾。

+ **优缺点：** 
    + 对各类型进程相对公平（FCFS的优点）；
    + 每个新到达的进程都可以很快就得到响应（RR的优点）；
    + 短进程只用较少的时间就可完成（SPF的优点）；
    + 不必实现估计进程的运行时间（避免用户估计出错）； 
    + 可灵活地调整对各类进程的偏好程度，比如CPU密集型进程、I/O密集型进程【拓展：可以将因I/O而阻塞的进程重新放回原队列，这样I/O型进程就可以保持较高优先级】

+ **是否会导致饥饿：** 会

>   例题：各进程到达就绪队列的时间、需要的运行时间如下表所示。使用多级反馈队列调度算法，分析进程运行的过程

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311548153.png" alt="image-20230531154834078" style="zoom:67%;" />

>   -   设置多级就绪队列，各级队列优先级从高到低，时间片从小到大 
>   -   新进程到达时先进入第1级队列，按FCFS原则排队等待被分配时间片。
>       -   若用完时间片进程还未结束，则进程进入下一级队列队尾。
>       -   如果此时已经在最下级的队列，则重新放回最下级队列队尾。 
>   -   只有第 k 级队列为空时，才会为 k+1 级队头的进程分配时间片；
>   -   被抢占处理机的进程重新放回原队列队尾。

-   小结

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311549029.png" alt="image-20230531154947942" style="zoom: 67%;" />

注：

-   比起早期的批处理操作系统来说，由于计算机造价大幅降低，因此之后出现的交互式操作系统（包括分时操作系统、实时操作系统等)更注重系统的响应时间、公平性、平衡性等指标。而这几种算法恰好也能较好地满足交互式系统的需求。
-   因此这三种算法**适合用于交互式系统**。（比如UNIX使用的就是多级反馈队列调度算法)

#### 3.7.8. 多级队列调度算法

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305311555414.png" alt="image-20230531155526287" style="zoom:67%;" />

### 3.8. 补充

+ 先来先服务调度算法有利于CPU繁忙型的作业，而不利于I/O繁忙型的作业。FCFS调度算法比较有利于长作业，而不利于短作业。所谓CPU繁忙型的作业，是指该类作业需要大量的CPU时间进行计算，而很少请求I/O操作。I/O繁忙型的作业是指CPU处理时，需要频繁地请求I/O操作。所以CPU繁忙型作业更接近于长作业。
+ 在同一台处理器上以单道方式运行时，多道作业同时到达的情况下，要想获得最短的平均周转时间，用短作业优先调度算法会有较好的效果。
+ 作业是从用户角度出发的，它由用户提交，以用户任务为单位；进程是从操作系统出发的，由系统生成，是操作系统的资源分配和独立运行的基本单位。
+ 中断向量本身是用于存放中断服务例行程序的入口地址，而中断向量地址就应是该入口地址的地址。
+ 短任务优先调度不管是抢占式的还是非抢占的，当系统总是出现新来的短任务时，长任务会总是得不到处理机，产生饥饿现象。
+ 多级反馈队列调度算法能较好地满足各种类型用户的需要。
    + 对于终端型作业用户而言，由于它们提交的作业大多属于交互型作业，作业通常比较短小，系统只要能使这些作业在第一级队列所规定的时间片内完成，便可使终端型作业用户感到满意；
    + 对于短批处理作业用户而言，它们的作业开始时像终端型作业一样，若仅在第一级队列中执行一个时间片即可完成，便可获得与终端型作业一样的响应时间；
    + 对于稍长的作业，通常也只需要在第2级队列和第3级队列中各执行一个时间片即可完成，其周转时间仍然较短；
    + 对于长批处理作业用户而言，它们的长作业将依次在第1，2，……，n级队列中运行，然后按时间片轮转方式运行，用户不必担心其作业长期得不到处理。


## 4. 进程同步

>   在OS中引入进程后，一方面可以使系统中的多道程序并发执行，这不仅能有效地改善资源利用率，还可显著地提高系统的吞吐量，但一方面却使系统变得更加复杂。如果不能采取有效的措施，对多个进程的运行进行妥善的管理，必然会因为执行进程对系统资源的无序争夺给系统造成混乱。致使每次处理的结果存在着不确定性，即显示出其不可再现性。即进程具有异步性的特征。异步性是指，各并发执行的进程以各自独立的、不可预知的速度向前推进。
>
>   为保证多个进程能有条不紊地运行，在多道程序系统中，必须引入进程同步机制。接下来会介绍单处理机系统中的进程同步机制——硬件同步机制、信号量机制、管程机制等，利用它们来保证程序执行的可再现性。

### 4.1. 进程同步的基本概念


进程同步机制的主要任务，是对多个相关进程在执行次序上进行协调，使并发执行的诸进程之间能按照一定的规则（或时序）共享系统资源，并能很好地相互合作，从而使程序的执行具有可再现性。

#### 4.1.1. 进程同步


同步亦称直接制约关系，是指为完成某种任务而建立的两个或多个进程，这些进程因为需要在某些位置上协调它们的工作次序而产生的制约关系。进程间的直接制约关系源于它们之间的相互合作。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201502329.png" alt="image-20230720150240227" style="zoom: 50%;" />


 例如，读进程和写进程并发运行，由于并发必然导致异步性，因此读进程和写进程两个操作的执行顺序是不确定的。而实际应用中，又必须按照“写进程→读进程”的顺序来执行。因为它们之间的相互合作，所以需要去协调它们的工作次序。

#### 4.1.2. 进程互斥


互斥又称间接制约关系。进程互斥指当一个进程访问某临界资源时，另一个想要访问该临界资源的进程必须等待。当前访问临界资源的进程访问结束，释放该资源之后，另一个进程才能去访问临界资源。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201502946.png" alt="image-20230720150212831" style="zoom: 67%;" />


例如，在仅有一台打印机（需要互斥访问）的系统中，有两个进程A和进程B，若进程A需要打印时，系统已将打印机分配给进程B，则进程A必须阻塞。一旦进程B将打印机释放，系统便将进程A唤醒，并将其由阻塞态变为就绪态。

#### 4.1.3. 临界资源


我们把**一个时间段内只允许一个进程使用的资源称为临界资源**。许多物理设备（比如摄像头、打印机）都属于临界资源。此外还有许多变量、数据、内存缓冲区等都属于临界资源。

对临界资源的访问，必须互斥地进行，在每个进程中，**访问临界资源的那段代码称为临界区，也称为临界段**。

为了保证临界资源的正确使用，可把临界资源的访问过程分成4个部分： 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201503723.png" alt=".*?" style="zoom:67%;" />

 注意： 临界区是进程中的**访问临界资源**的代码段。 进入区和退出区是**负责实现互斥**的代码段。

#### 4.1.4. 同步机制应遵循的规则


为了实现对临界资源的互斥访问，同时保证系统整体性能，需要遵循以下原则：


+ **空闲让进**。临界区空闲时，可以允许一个请求进入临界区的进程立即进入临界区；
+ **忙则等待**。当已有进程进入临界区时，其他试图进入临界区的进程必须等待；
+ **有限等待**。对请求访问的进程，应保证能在有限时间内进入临界区（保证不会饥饿）；
+ **让权等待**。当进程不能进入临界区时，应立即释放处理机，防止进程忙等待。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201503140.png" alt="image-20230720150335944" style="zoom: 67%;" />


### 4.2. 实现临界区互斥的基本方法


如果没有注意进程互斥的话，将会出现以下现象： 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201503278.png" alt="image-20230720150359216" style="zoom:50%;" />


 先调度A上处理机运行，当A在使用打印机的过程中，分配给它的时间片用完了，接下来操作系统调度B让它上处理机运行，进程B也在使用打印机。 结局：A、B 的打印内容混在一起了。

而想要实现互斥可以看一下下面介绍的方法。

#### 4.2.1. 软件实现方法

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305312152559.png" alt="image-20230531215219462" style="zoom:67%;" />


##### 4.2.1.1. 单标志法

**算法思想**：两个进程在访问完临界区后会把使用临界区的权限转交给另一个进程。也就是说每个进程进入临界区的权限只能被另一个进程赋予。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201504473.png" alt=".*?" style="zoom:50%;" />

1.   turn 的初值为 0，即刚开始只允许 0 号进程进入临界区。 
2.   若 P1 先上处理机运行，则会一直卡在 ⑤。直到 P1 的时间片用完，发生调度，切换 P0 上处理机运行。
3.   代码 ① 不会卡住 P0，P0 可以正常访问临界区，在 P0 访问临界区期间即时切换回 P1，P1依然会卡在 ⑤。
4.   只有 P0 在退出区将 turn 改为 1 后，P1才能进入临界区。 
5.   因此，该算法可以实现“同一时刻最多只允许一个进程访问临界区”。

类比一下生活中的例子： 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201504683.png" alt=".*?" style="zoom: 50%;" />

 而这种算法只能按 P0 → P1 → P0 → P1 →……这样轮流访问。

-   这种必须“轮流访问”带来的问题是，如果此时允许进入临界区的进程是 P0，而 P0 一直不访问临界区，那么虽然此时临界区空闲，但是并不允许 P1 访问。 因此，单
-   **标志法存在的主要问题是：违背“空闲让进”原则。**

##### 4.2.1.2. 双标志先检查法

**算法思想**：设置一个布尔型数组 flag[]，数组中各个元素用来标记各进程想进入临界区的意愿，比如 “flag[0] = ture”意味着 0 号进程 P0 现在想要进入临界区。每个进程在进入临界区之前先检查当前有没有别的进程想进入临界区，如果没有，则把自身对应的标志 flag[i] 设为 true，之后开始访问临界区。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201505214.png" alt=".*?" style="zoom: 50%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201505945.png" alt=".*?" style="zoom: 50%;" />

 若按照 ①⑤②⑥③⑦….的顺序执行，P0 和 P1 将会同时访问临界区。 

-   因此，**双标志先检查法的主要问题是：违反“忙则等待”原则。****不能实现**对临界资源的**互斥访问**。
-   原因在于，进入区的“检查”和“上锁” 两个处理不是一气呵成的。<u>“检查”后，“上锁”前可能发生进程切换。</u>

##### 4.2.1.3. 双标志后检查法

**算法思想**：双标志先检查法的改版。前一个算法的问题是先“检查”后“上锁”，但是这两个操作又无法一气呵成，因此导致了两个进程同时进入临界区的问题。因此，人们又想到先“上锁”后“检查”的方法，来避免上述问题。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201506958.png" alt=".*?" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201506824.png" alt=".*?" style="zoom:50%;" />

 若按照 ①⑤②⑥….的顺序执行，P0 和 P1 将都无法进入临界区。 

-   因此，双标志后检查法虽然解决了“忙则等待”的问题，但是**又违背了“空闲让进”和“有限等待”原则**，会因各进程都长期无法访问临界资源而**产生“饥饿”现象**。 

-   两个进程都争着想进入临界区，但是谁也不让谁，最后谁都无法进入临界区，就发生了**死锁**。

##### 4.2.1.4. Peterson算法

**算法思想**：结合双标志法、单标志法的思想。如果双方都争着想进入临界区，那可以让进程尝试“孔融让梨”（谦让）。做一个有礼貌的进程。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201507554.png" alt=".*?" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201509352.png" alt="image-20230720150938228" style="zoom: 67%;" />

-    Peterson 算法用软件方法**解决了进程互斥问题，遵循了空闲让进、忙则等待、有限等待三个原则**，
-   但是依然**未遵循让权等待**的原则。 
-   Peterson 算法相较于之前三种软件解决方案来说，是最好的，但依然不够好。

#### 4.2.2. 硬件实现方法


通过硬件支持实现临界段问题的方法称为低级方法，或称元方法。

##### 4.2.2.1. 中断屏蔽方法

**利用“开/关中断指令”实现**（与原语的实现思想相同，即在某进程开始访问临界区到结束访问为止都不允许被中断，也就不能发生进程切换，因此也不可能发生两个同时访问临界区的情况）。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305312156634.png" alt="image-20230531215623568" style="zoom:67%;" />

-   优点：简单、高效。 
-   缺点：不适用于多处理机（因为一个处理机的关中断指令对另外一个处理机并不影响，所以有可能多个处理机同时进入临界区的情况），只适用单处理机；只适用于操作系统内核进程，不适用于用户进程（因为开/关中断指令只能运行在内核态，这组指令如果能让用户随意使用会很危险，滥用）

##### 4.2.2.2. TestAndSet指令

-   简称 TS 指令，也有地方称为 TestAndSetLock 指令，或 TSL 指令。 
-   TSL 指令是**用硬件实现的**，执行的过程不允许被中断，只能一气呵成。

以下是用C语言描述的逻辑： 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201510390.png" alt=".*?" style="zoom: 50%;" />

 若刚开始 lock 是 false，则 TSL 返回的 old 值为 false，while 循环条件不满足，直接跳过循环，进入临界区。

若刚开始 lock 是 true，则执行 TLS 后 old 返回的值为 true，while 循环条件满足，会一直循环，直到当前访问临界区的进程在退出区进行“解锁”。 

相比软件实现方法（双标志先检查法），TSL 指令把“上锁”和“检查”操作**用硬件的方式变成了一气呵成的原子操作**。

-   优点：实现简单，无需像软件实现方法那样严格检查是否会有逻辑漏洞；适用于多处理机环境。 
-   缺点：**不满足“让权等待”原则**，暂时无法进入临界区的进程会占用CPU并循环执行TSL指令，从而导致“忙等”。

##### 4.2.2.3. Swap指令

-   有的地方也叫 Exchange 指令，或简称 XCHG 指令。
-   Swap 指令是**用硬件实现的，执行的过程不允许被中断，只能一气呵成**。

以下是用C语言描述的逻辑： 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201510893.png" alt=".*?" style="zoom:50%;" />


 **逻辑上来看 Swap 和 TSL 并无太大区别**，都是先记录下此时临界区是否已经被上锁（记录在 old 变量上），再将上锁标记 lock 设置为 true，最后检查 old，如果 old 为 false 则说明之前没有别的进程对临界区上锁，则可跳出循环，进入临界区。

-   优点：实现简单，无需像软件实现方法那样严格检查是 否会有逻辑漏洞；适用于多处理机环境。 
-   缺点：**不满足“让权等待”原则**，暂时无法进入临界区的进程会占用CPU并循环执行TSL指令，从而导致“忙等”。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202305312204959.png" alt="image-20230531220425867" style="zoom: 67%;" />

### 4.3. 互斥锁

-   解决临界区最简单的工具就是互斥锁(mutex lock)。
-   一个进程在进入临界区时应获得锁；在退出临界区时释放锁。
-   函数`acquire()`获得锁，而函数`release()`释放锁。
-   每个互斥锁有一个布尔变量`available`,表示锁是否可用。如果锁是可用的，调用`acqiure()`会成功，且锁不再可用。当一个进程试图获取不可用的锁时，会被阻塞，直到锁被释放。

```C
    acquire() {
        while(!available);	//忙等待
        available false;	//获得锁	    
    }

    release(){
        available = true;	//释放锁
    }
```

-   `acquire()`或`release()`的执行必须是**原子操作**，因此互斥锁通常**采用硬件机制**来实现。
-   互斥锁的**主要缺点是忙等待**，当有一个进程在临界区中，任何其他进程在进入临界区时必须连续循环调用`acquire()`。当多个进程共享同一CPU时，就浪费了CPU周期。
-   因此，互斥锁**通常用于多处理器系统**，一个线程可以在一个处理器上等待，不影响其他线程的执行。
-   自旋锁（spin lock）
    -   需要连续循环忙等的互斥锁，都可称为自旋锁(spin lock)。
    -   如TSL指令、swap指令、单标志法。
-   特性
    -   需忙等，进程时间片用完才下处理机，**违反“让权等待”。**
    -   优点：等待期间不用切换进程上下文，**多处理器系统中，若上锁的时间短，则等待代价很低**
    -   **常用于多处理器系统**，一个核忙等，其他核照常工作，并快速释放临界区
    -   不太适用于单处理机系统，忙等的过程中不可能解锁

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306011711383.png" alt="image-20230601171149288" style="zoom: 67%;" />

### 4.4. 信号量

进程互斥的四种软件实现方式（单标志法、双标志先检查、双标志后检查、Peterson算法） 

进程互斥的三种硬件实现方法（中断屏蔽方法、TS/TSL指令、Swap/XCHG指令）


+ 在双标志先检查法中，进入区的“检查”、“上锁” 操作无法一气呵成，从而导致了两个进程有可能同时进入临界区的问题；
+ 所有的解决方案都无法实现“让权等待”。



1965年，荷兰学者Dijkstra提出了一种卓有成效的实现进程互斥、同步的方法——信号量机制。

用户进程可以通过使用操作系统提供的一对原语来对信号量进行操作，从而很方便的实现了进程互斥、进程同步。

-   信号量其实就是一个变量 ，可以用一个信号量来表示系统中某种资源的数量，比如：系统中只有一台打印机，就可以设置一个初值为 1 的信号量。

-   原语是一种特殊的程序段，其执行只能一气呵成，不可被中断。**原语是由关中断/开中断指令实现的。**软件解决方案的主要问题是由“进入区的各种操作无法一气呵成”，因此如果能把进入区、退出区的操作都用“原语”实现，使这些操作能“一气呵成”就能避免问题。

-   一对原语：**wait(S) 原语和 signal(S) 原语**，它们在执行时是不可中断的，可以把原语理解为我们自己写的函数，函数名分别为 wait和 signal，括号里的信号量 S 其实就是函数调用时传入的一个参数。 wait、signal 原语常简称为 P、V操作（来自荷兰语 proberen 和 verhogen）。因此，做题的时候常把wait(S)、signal(S) 两个操作分别写为 P(S)、V(S)。

#### 4.4.1. 整型信号量

-   用一个整数型的变量作为信号量，用来表示系统中某种资源的数量。
-   与普通整数变量的区别：对信号量的操作只有三种，即 初始化、P操作、V操作

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201511453.png" alt=".*?" style="zoom:50%;" />


 存在的问题：**不满足“让权等待”原则**，会发生“忙等”。

#### 4.4.2. 记录型信号量


整型信号量的缺陷是存在“忙等”问题，因此人们又提出了“记录型信号量”，<u>即用记录型数据结构表示的信号量。</u> 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201511938.png" alt=".*?" style="zoom:50%;" />


 在考研题目中 wait(S)、signal(S) 也可以记为 P(S)、V(S)，这对原语可用于实现**系统资源的“申请”和“释放”。**

-   S.value 的初值表示系统中某种资源的数目。
    -   对信号量 S 的一次P操作意味着进程请求一个单位的该类资源，因此需要执行 S.value --，表示资源数减1，当S.value < 0 时表示该类资源已分配完毕，因此进程应调用 block 原语进行自我阻塞（当前运行的进程从运行态→阻塞态），主动放弃处理机，并插入该类资源的等待队列 S.L 中。可见，该机制遵循了“让权等待”原则，不会出现“忙等”现象。
    -   对信号量 S 的一次 V 操作意味着进程释放一个单位的该类资源，因此需要执行 S.value ++，表示资源数加1，若加1后仍是 S.value <= 0，表示依然有进程在等待该类资源，因此应调用 wakeup 原语唤醒等待队列中的第一个进程（被唤醒进程从阻塞态→就绪态）。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201511687.png" alt=".*?" style="zoom: 50%;" />

>   注：
>
>   -   若考试中出现 P(S)、V(S) 的操作，除非特别说明，否则默认 S 为记录型信号量，都采用记录型信号量进行解题。
>   -   一个信号量对应一种资源。 信号量的值 = 这种资源的剩余数量（信号量的值如果小于0，说明此时有进程在等待这种资源） 
>   -   P( S ) —— 申请一个资源S，如果资源不够就阻塞等待 
>   -   V( S ) —— 释放一个资源S，如果有进程在等待该资源，则唤醒一个进程

#### 4.4.3. 利用信号量实现进程互斥

+ 分析并发进程的关键活动，划定临界区（如：对临界资源打印机的访问就应放在临界区）
+ 设置互斥信号量 mutex，初值为 1（理解：信号量 mutex 表示“进入临界区的名额”）
+ 在进入区 P(mutex)——申请资源
+ 在退出区 V(mutex)——释放资源

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201512204.png" alt=".*?" style="zoom:50%;" />

>   注意：
>
>   -   对不同的临界资源需要设置不同的互斥信号量。P、V操作必须成对出现。
>   -   缺少P(mutex) 就不能保证临界资源的互斥访问。
>   -   缺少 V(mutex) 会导致资源永不被释放，等待进程永不被唤醒。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201513199.png" alt="image-20230720151348084" style="zoom:80%;" />


#### 4.4.4. 利用信号量实现进程同步


进程同步：要让各并发进程按要求有序地推进。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201514908.png" alt=".*?" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201514224.png" alt=".*?" style="zoom: 50%;" />


 用信号量实现进程同步：


+ 分析什么地方需要实现“同步关系”，即必须保证“一前一后”执行的两个操作（或两句代码）
+ 设置同步信号量 S, 初始为 0
+ **在“前操作”之后执行 V(S)**
+ **在“后操作”之前执行 P(S) <u>（技巧口诀：前V后P）</u>**


#### 4.4.5. 利用信号量实现前驱关系

-   **前驱关系**是表示进程之间执行的先后顺序。P1→P2表示P2开始执行之前P1必须完成。

进程 P1 中有句代码 S1，P2 中有句代码 S2 ，P3中有句代码S3 …… P6 中有句代码 S6。这些代码要求按如下前驱图所示的顺序来执行： 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201514902.png" alt=".*?" style="zoom:67%;" />


 其实每一对前驱关系都是一个进程同步问题（需要保证一前一后的操作）因此，


+ 要为每一对前驱关系各设置一个同步信号量
+ 在“前操作”之后对相应的同步信号量执行 V 操作
+ 在“后操作”之前对相应的同步信号量执行 P 操作 （前V后P）

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201515974.png" alt=".*?" style="zoom:67%;" />


### 4.5. 管程


在信号量机制中，每个要访问临界资源的进程都必须自备同步的PV操作，大量分散的同步操作给系统管理带来了麻烦，且容易因同步操作不当而导致死锁。如在生产者消费者问题中的同步操作不当就会导致死锁，如下图所示： 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201515298.png" alt=".*?" style="zoom:67%;" />


 于是，便产生了一种新的进程同步工具——**管程**（管理临界资源的进程）。管程的特性保证了进程互斥，无须程序员自己实现互斥，从而降低了死锁发生的可能性。同时管程提供了条件变量，可以让程序员灵活地实现进程同步。

#### 4.5.1. 管程的定义


代表共享资源的数据结构以及由对该共享数据结构实施操作的一组过程所组成的资源管理程序共同构成了一个操作系统的资源管理模块，我们称之为管程（monitor）。


+  管程是一种特殊的软件模块，有这些部分组成： 

    +  ① 局部于管程的共享数据结构说明； 
    +  ② 对该数据结构进行操作的一组过程（也可以理解为“函数”）； 
    +  ③ 对局部于管程的共享数据设置初始值的语句； 
    +  ④ 管程有一个名字。 

+  管程的基本特征： 

    +  ① 局部于管程的数据只能被局部于管程的过程所访问； 
    +  ② 一个进程只有通过调用管程内的过程才能进入管程访问共享数据； 
    +  ③ 每次仅允许一个进程在管程内执行某个内部过程。 

+  管程的定义描述举例如下： 

<img src="./figures\12894f077a8f45a1a6d45e777a4d9669.png" alt=".*?" style="zoom:50%;" />


+  ①管程把对共享资源的操作封装起来（整体上很像一个类），管程内的共享数据结构只能被管程内的过程所访问。一个进程只有通过调用管程内的过程才能加入管程访问共享资源。对于上例，外部进程只能通过调用take_away()过程来申请一个资源；归还资源也一样。 
+  ②每次仅允许一个进程加入管程，从而实现进程互斥（注意：这种**互斥特性是由编译器负责实现的**，程序员不用关心）。若多个进程同时调用take_away()，give_back()，则只有某个进程运行完它调用的过程后，下个进程才能开始运行它调用的过程。也就是说，各个进程只能串行执行管理内的过程，这一特性保证了进程“互斥”访问共享数据结构S。 

+  管程和进程的不同： 
    +  ① 虽然两者都定义了数据结构，但进程定义的是私有数据结构PCB，管程定义的是公共数据结构，如消息队列等； 
    +  ② 两者都存在对各自数据结构上的操作；但进程是由顺序程序执行有关操作，而管程主要是进行同步操作和初始化操作； 
    +  ③ 设置进程的目的在于实现系统的并发性，而管程的设置则是解决共享资源的互斥使用问题； 
    +  ④ 进程通过调用管程中的过程对共享数据结构实行操作，进程是主动工作方式，而管程为被动工作方式； 
    +  ⑤ 进程之间能并发执行，而管程则不能与其调用者并发； 
    +  ⑥ 进程具有动态性，由“创建”而诞生，由“撤销”而消亡，而管程则是操作系统中的一个资源管理模块，供进程调用。 

#### 4.5.2. 条件变量


当一个进程进入管程后被阻塞，直到阻塞原因解除是，在此期间，如果该进程不释放管程，你们其他管程无法进入管程，被迫长时间的等待。为此，将阻塞原因定义为**条件变量 condition**。通常，一个进程被阻塞的原因可以有多个，因此在管程中设置了多个条件变量。每个条件变量保存了一个等待队列，用于记录该条件变量对应被阻塞的所有进程，对条件变量只能进行两种操作，即wait和signal。

x.wait：当x对应的条件不满足时，正在调用管程的进程调用x.wait将自己插入x条件的等待队列，并释放管程。此时其他进程可以使用该管程。 

x.signal：x对应的条件发生了变化，则调用x.signal，唤醒一个因x条件而阻塞的进程。

条件变量和信号量的比较：


+ 相似点：条件变量的wait/signal操作类似于信号量的P/V操作，可以实现进程的阻塞/唤醒。
+ 不同点：条件变量是“没有值”的，仅实现了“排队等待”功能；而信号量是“有值”的，信号量的值反映了剩余资源数，而在管程中，剩余资源数用共享数据结构记录。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306012317842.png" alt="image-20230601231718735" style="zoom:50%;" />

### 4.6. 经典同步问题


#### 4.6.1. 生产者-消费者问题

+ **问题描述**： 系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品放入缓冲区，消费者进程每次从缓冲区中取出一个产品并使用。（注：这里的“产品”理解为某种数据）生产者、消费者共享一个初始为空、大小为n的缓冲区。只有缓冲区没满时，生产者才能把产品放入缓冲区，否则必须等待（满则阻塞等待）。只有缓冲区不空时，消费者才能从中取出产品，否则必须等待（空则阻塞等待）。缓冲区是临界资源，各进程必须互斥地访问。
+ **问题分析**： 
    + 系统中有一组生产者进程和一组消费者进程，生产者进程每次生产一个产品放入缓冲区，消费者进程每次从缓冲区中取出一个产品并使用。（注：这里的“产品”理解为某种数据） 
    + 生产者、消费者共享一个初始为空、大小为n的缓冲区。 
        + 只有缓冲区没满时，生产者才能把产品放入缓冲区，否则必须等待。（同步关系。缓冲区满时，生产者要等待消费者取走产品） 
        + 只有缓冲区不空时，消费者才能从中取出产品，否则必须等待。（同步关系。缓冲区空时（即没有产品时），消费者要等待生产者放入产品） 
        + 缓冲区是临界资源，各进程必须互斥地访问。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306012133232.png" alt="image-20230601213322123" style="zoom: 33%;" />

+ **PV操作题目分析步骤**： 
  
+ 关系分析。找出题目中描述的各个进程，分析它们之间的同步、互斥关系。
+ 整理思路。根据各进程的操作流程确定P、V操作的大致顺序。
+ 设置信号量。并根据题目条件确定信号量初值。（互斥信号量初值一般为1，同步信号量的初始值要看对应资源的初始值是多少）

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306012240078.png" alt="image-20230601224012993" style="zoom:50%;" />


 4. **能否改变相邻P、V操作的顺序？** 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306012252044.png" alt="image-20230601225230975" style="zoom:50%;" />

若此时缓冲区内已经放满产品，则 empty=0，full=n。 则生产者进程执行① 使mutex变为0，再执行②，由于已没有空闲缓冲区，因此生产者被阻塞。 由于生产者阻塞，因此切换回消费者进程。消费者进程执行③，由于mutex为0，即生产者还没释放对临界资源的“锁”，因此消费者也被阻塞。 这就造成了生产者等待消费者释放空闲缓冲区，而消费者又等待生产者释放临界区的情况，生产者和消费者循环等待被对方唤醒，出现“死锁”。 同样的，若缓冲区中没有产品，即full=0，empty=n。按③④① 的顺序执行就会发生死锁。 因此，实现互斥的P操作一定要在实现同步的P操作之后。 V操作不会导致进程阻塞，因此两个V操作顺序可以交换。 

>   5. **利用管程解决生产者-消费者问题** 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306012253454.png" alt="image-20230601225303339" style="zoom:50%;" />


 引入管程的目的无非就是要更方便地实现进程互斥和同步。


+ 需要在管程中定义共享数据（如生产者消费者问题的缓冲区）。
+ 需要在管程中定义用于访问这些共享数据的“入口”——其实就是一些函数（如生产者消费者问题中，可以定义一个函数用于将产品放入缓冲区，再定义一个函数用于从缓冲区取出产品）。
+ 只有通过这些特定的“入口”才能访问共享数据。
+ 管程中有很多“入口”，但是每次只能开放其中一个“入口”，并且只能让一个进程或线程进入（如生产者消费者问题中，各进程需要互斥地访问共享缓冲区。管程的这种特性即可保证一个时间段内最多只会有一个进程在访问缓冲区。注意：这种互斥特性是由编译器负责实现的，程序员不用关心）
+ 可在管程中设置条件变量及等待/唤醒操作以解决同步问题。可以让一个进程或线程在条件变量上等待（此时，该进程应先释放管程的使用权，也就是让出“入口”）；可以通过唤醒操作将等待在条件变量上的进程或线程唤醒。


程序员可以用某种特殊的语法定义一个管程（比如: monitor ProducerConsumer …… end monitor;），之后其他程序员就可以使用这个管程提供的特定“入口”很方便地使用实现进程同步/互斥了。

#### 4.6.2. 多生产者-多消费者

+  **问题描述：** 桌子上有一只盘子，每次只能向其中放入一个水果。爸爸专向盘子中放苹果，妈妈专向盘子中放橘子，儿子专等着吃盘子中的橘子，女儿专等着吃盘子中的苹果。只有盘子空时，爸爸或妈妈才可向盘子中放一个水果。仅当盘子中有自己需要的水果时，儿子或女儿可以从盘子中取出水果。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306012256136.png" alt="image-20230601225636048" style="zoom: 33%;" />

+  **问题分析：**


+ 关系分析。找出题目中描述的各个进程，分析它们之间的同步、互斥关系。由于每次只能向其中放入一只水果可知，爸爸和妈妈是互斥关系。爸爸和女儿、妈妈和儿子是同步关系。儿子和女儿之间没有互斥和同步关系。
+ 整理思路。根据各进程的操作流程确定P、V操作的大致顺序。（互斥：在临界区前后分别PV；同步：前V后P）
+ 设置信号量。设置需要的信号量，并根据题目条件确定信号量初值。（互斥信号量初值一般为1，同步信号量的初始值要看对应资源的初始值是多少） 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306012255749.png" alt="image-20230601225551668" style="zoom: 50%;" />


+  **实现过程：** 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306012259553.png" alt="image-20230601225917480" style="zoom:50%;" />

-   图中还有一个问题：可不可以不用互斥信号量？ 

刚开始，儿子、女儿进程即使上处理机运行也会被阻塞。如果刚开始是父亲进程先上处理机运行，则：父亲 P(plate)，可以访问盘子→母亲 P(plate)，阻塞等待盘子→父亲放入苹果 V(apple)，女儿进程被唤醒，其他进程即使运行也都会阻塞，暂时不可能访问临界资源（盘子）→女儿 P(apple)，访问盘子，V(plate)，等待盘子的母亲进程被唤醒→母亲进程访问盘子（其他进程暂时都无法进入临界区）→…… 

原因在于：本题中的缓冲区大小为1，在任何时刻，apple、orange、plate 三个同步信号量中最多只有一个是1。因此在任何时刻，最多只有一 

**结论：即使不设置专门的互斥变量mutex，也不会出现多个进程同时访问盘子的现象。** 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201517706.png" alt="image-20230720151753613" style="zoom: 67%;" />

-   扩展：如果盘子容量为2呢？ 如果盘子容量为2的话，即plate初始化为2。 
    -   结论：父亲 P(plate)，可以访问盘子→母亲 P(plate)，可以访问盘子→父亲在往盘子里放苹果，同时母亲也可以往盘子里放橘子。于是就出现了两个进程同时访问缓冲区的情况，有可能导致两个进程写入缓冲区的数据相互覆盖的情况。 

**总结：**在生产者-消费者问题中，**如果缓冲区大小为1，那么有可能不需要设置互斥信号量就可以实现互斥访问缓冲区的功能。**当然，这不是绝对的，要具体问题具体分析。 

**建议：**在考试中如果来不及仔细分析，可以加上互斥信号量，保证各进程一定会互斥地访问缓冲区。但需要注意的是，实现互斥的P操作一定要在实现同步的P操作之后，否则可能引起“死锁”。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201518920.png" alt=".*?" style="zoom: 50%;" />

#### 4.6.3. 吸烟者问题

+  **问题描述：** 假设一个系统有三个抽烟者进程和一个供应者进程。每个抽烟者不停地卷烟并抽掉它，但是要卷起并抽掉一支烟，抽烟者需要有三种材料：烟草、纸和胶水。三个抽烟者中，第一个拥有烟草、第二个拥有纸、第三个拥有胶水。供应者进程无限地提供三种材料，供应者每次将两种材料放桌子上，拥有剩下那种材料的抽烟者卷一根烟并抽掉它，并给供应者进程一个信号告诉完成了，供应者就会放另外两种材料再桌上，这个过程一直重复*（让三个抽烟者轮流地抽烟）* 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201519164.png" alt="image-20230720151912034" style="zoom:67%;" />

+  **问题分析：** 本质上这题也属于“生产者-消费者”问题，更详细的说应该是“可生产多种产品的单生产者-多消费者”。


+ 关系分析。供应者与三个抽烟者分别是同步关系。由三个抽烟者轮流抽烟，所以三个抽烟者对抽烟这个动作互斥。
+ 整理思路。显然这里有4个进程。供应者作为生产者向三个抽烟者提供材料。
+ 设置信号量。

    + 信号量offer1，offer2，offer3分别表示烟草和纸组合的资源、烟草和胶水组合的资源、纸和胶水组合的资源。
    + 信号量finish用于互斥进行抽烟动作。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201519400.png" alt=".*?" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201520914.png" alt=".*?" style="zoom: 50%;" />

+  **实现过程：** 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201521607.png" alt="image-20230720152154498" style="zoom: 50%;" />


 吸烟者问题可以为我们解决“可以生产多个产品的单生产者”问题提供一个思路。 值得吸取的精华是：“轮流让各个吸烟者吸烟”必然需要“轮流的在桌上放上组合一、二、三”，注意体会我们是如何用一个整型变量 i 实现这个“轮流”过程的。 


#### 4.6.4. 读者-写者问题

+  **问题描述：** 有读者和写者两组并发进程，共享一个文件，当两个或两个以上的读进程同时访问共享数据时不会产生副作用，但若某个写进程和其他进程（读进程或写进程）同时访问共享数据时则可能导致数据不一致的错误。因此要求：
    +  ①允许多个读者可以同时对文件执行读操作；
    +  ②只允许一个写者往文件中写信息；
    +  ③任一写者在完成写操作之前不允许其他读者或写者工作；
    +  ④写者执行写操作前，应让已有的读者和写者全部退出。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201522349.png" alt=".*?" style="zoom:50%;" />

+  **问题分析：**
    +  关系分析。由题目分析读者和写者是互斥的，写者和写者也是互斥的，而读者和读者不存在互斥问题。
    +  整理思路。两个进程，即读者和写者。写者和任何进程互斥，用互斥信号量P、V即可解决。读者必须在实现与写者互斥的同时，实现与其他读者的同步，需要多用到一个计数器来判断当前是否有读者读文件。当有读者时，写者是无法写文件的，此时读者会一直占用文件；当没有读者时，写者才可以写文件。同时，这里不同读者对计数器的访问也应该是互斥的。
    +  信号量设置。


+ **实现过程：** 当信号量只有计数器和用于实现对共享文件的互斥访问rw时。
+ 思考：若两个读进程并发执行，则 count=0 时两个进程也许都能满足 if 条件，都会执行P(rw)，从而使第二个读进程阻塞的情况。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201524707.png" alt=".*?" style="zoom: 50%;" />

-   如何解决：出现上述问题的原因在于对count 变量的检查和赋值无法一气呵成，因此可以设置另一个互斥信号量来保证各读进程对count 的访问是互斥的。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201524799.png" alt=".*?" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201526506.png" alt=".*?" style="zoom: 50%;" />


 若希望写进程优先，即当有读进程正在读共享文件时，即当有读进程正在读共享文件时，有写进程请求访问，这时应禁止后续读进程的请求，等到已在共享文件的读进程执行完毕，立即让写进程执行，只有在无写进程执行的情况下才允许读进程再次运行。因此，增加了一个信号量w。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201527181.png" alt=".*?" style="zoom:50%;" />

+  **总结：** 读者-写者问题为我们解决复杂的互斥问题提供了一个参考思路。 其核心思想在于设置了一个计数器 count 用来记录当前正在访问共享文件的读进程数。我们可以用count 的值来判断当前进入的进程是否是第一个/最后一个读进程，从而做出不同的处理。另外，对 count 变量的检查和赋值不能一气呵成导致了一些错误，如果需要实现“一气呵成”，自 然应该想到用互斥信号量。 


#### 4.6.5. 哲学家进餐问题

+  **问题描述：** 一张圆桌上坐着5名哲学家，每两个哲学家之间的桌上摆一根筷子，桌子的中间是一碗米饭。哲学家们倾注毕生的精力用于思考和进餐，哲学家在思考时，并不影响他人。只有当哲学家饥饿时，才试图拿起左、右两根筷子（一根一根地拿起）。如果筷子已在他人手上，则需等待。饥饿的哲学家只有同时拿起两根筷子才可以开始进餐，当进餐完毕后，放下筷子继续思考。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201527827.png" alt="image-20230720152736684" style="zoom:67%;" />

+  **问题分析：**
    + 关系分析。系统中有5个哲学家进程，5位哲学家与左右邻居对其中间筷子的访问是互斥关系。
    + 整理思路。这个问题中只有互斥关系，但与之前遇到的问题不同的事，每个哲学家进程需要同时持有两个临界资源才能开始吃饭。如何避免临界资源分配不当造成的死锁现象，是哲学家问题的精髓。
    + 信号量设置。   
      + 定义互斥信号量数组chopstick[5]={1,1,1,1,1} 用于实现对5个筷子的互斥访问。    
      + 并对哲学家按0~4编号，哲学家 i 左边的筷子编号为 i，右边的筷子编号为 (i + 1)%5。
+  **实现过程：** 当5名哲学家都想要进餐并分别拿起左边的筷子时（都恰好执行完P(chopstick[i])）筷子已被拿光，等到他们想再拿右边的筷子时就会全被阻塞，因此出现了死锁。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201529266.png" alt=".*?" style="zoom:50%;" />

-    所以这时出现了一个问题，**如何防止死锁的发生呢？** 
     -   ① 可以对哲学家进程施加一些限制条件，比如最多允许四个哲学家同时进餐。这样可以保证至少有一个哲学家是可以拿到左右两只筷子的。（破坏互斥条件） 第①中的代码如下： <img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201529377.png" alt=".*?" style="zoom:67%;" />
     -   ②要求奇数号哲学家先拿左边的筷子，然后再拿右边的筷子，而偶数号哲学家刚好相反。用这种方法可以保证如果相邻的两个奇偶号哲学家都想吃饭，那么只会有其中一个可以拿起第一只筷子，另一个会直接阻塞。这就避免了占有一支后再等待另一只的情况。 
     -   ③ 仅当一个哲学家左右两支筷子都可用时才允许他抓起筷子。（破坏请求和保持条件) 第③种情况的代码实现如下： 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201530820.png" alt=".*?" style="zoom:67%;" />

+  **总结：** 哲学家进餐问题的关键在于解决进程死锁。 这些进程之间只存在互斥关系，但是与之前接触到的互斥关系不同的是，**每个进程都需要同时持有两个临界资源，因此就有“死锁”问题的隐患**。 如果在考试中遇到了一个进程需要同时持有多个临界资源的情况，应该参考哲学家问题的思想，分析题中给出的进程之间是否会发生循环等待，是否会发生死锁。可以参考哲学家就餐问题解决死锁的三种思路。 


### 4.7. 补充

+ 在多道程序技术中，信号量机制是一种有效实现进程同步和互斥的工具。进程执行的前趋关系实质上是指进程的同步关系。
+ 临界资源是互斥共享资源，非共享数据不属于临界资源。临界资源与共享资源的区别在于，在一段时间内能否允许被多个进程访问（并发使用）。公共队列可供多个进程使用，但一次只可供一个进程使用，若多个进程同时使用公共队列的话，势必造成队列中的数据混乱而无法使用，所以公共队列属于临界资源。而磁盘存储介质和可重入的程序代码（一次可供多个进程使用）都属于共享资源。
+ 在操作系统中，要对并发进程进行同步的原因是并发进程是异步的。
+ 在操作系统中，P、V操作是一种低级的进程通信原语，它是不能被中断的。不属于系统调用。
+ 原语是不可分割的指令序列。是原子性的、不可分割的操作。其严格定义为：由若干机器指令构成的完成某种特定功能的一段程序，其执行必须是连续的，在执行过程中不允许被中断。
+ 在信号量机制实现互斥时，互斥信号量的初值为1；而实现同步时，同步信号量的初值由用户确定，是根据具体情况来决定的。
+ 可以被多个进程在任意时刻共享的代码必须是不允许任何修改的代码。这样的代码就是可重入代码，也称纯代码，即允许多个进程同时访问的代码。所以共享程序段必须可重入编码，否则无法实现共享的功能。
+ 一个进程因在互斥信号量mutex上执行V(mutex)操作而导致唤醒另一个进程时，执行V操作后mutex的值小于等于0。因为系统原来存在等待进入临界区的进程，mutex小于等于-1。
+ 管程的signal操作与信号量机制中的V操作不同，信号量机制中的V操作一定会改变信号量的值S=S
+1.而管程中的signal操作时针对某个条件变量的，若不存在因该条件而阻塞的进程，则signal不会产生任何影响。
+ 并发进程之间的共享没有必然的要求，只有执行时间上的偶然重合，可能无关也可能有交往。
+ 若x是管程内的条件变量，则当进程执行x.wait()时所做的动作是阻塞该进程，并将之插入x的阻塞队列中。在同一时刻，管程中只能有一个进程在执行。若进程A执行了x.wait()操作，则该进程会阻塞，并挂到条件变量x对应的阻塞队列上。这样，管程的使用权被释放，就可以有另一个进程进入管程，所以这时要是有进程B执行x.signal()操作，则会唤醒x队列的阻塞队列的队首进程。wait和signal操作有点类似于信号量的P、V操作，不过P、V操作会对信号量进行修改操作、简称操作以及在信号量在满足一定条件的情况下将进程阻塞或唤醒；而管程下的wait和signal操作只实现了对进程的阻塞或唤醒。
+ 硬件方法实现进程同步时不能实现让权等待；Peterson算法满足有限等待但不满足让权等待；记录型信号量由于引入阻塞机制，消除了不让权等待的情况。
+ 实现临界区互斥机制不一定非要实现“让权等待”准则，如Peterson算法。

## 5. 死锁

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306012327201.png" alt="image-20230601232726090" style="zoom: 67%;" />


### 5.1. 死锁的概念


#### 5.1.1. 资源问题


在系统许多不同类型的资源中，其中可以引起死锁的主要是，需要采用互斥访问方法的、不可以背抢占的资源，即临界资源。

##### 5.1.1.1. 可重用性资源

可重用性资源是一种可供用户重复使用多次的资源，它具有如下性质：


+ 每一个可重用性资源中的单元只能分配给一个进程使用，不允许多个进程共享。
+ 进程在使用可重用性资源是，须按照这样的顺序： 

    + ① 请求资源。如果请求资源失败，请求进程将会被阻塞或循环等待。 
    + ② 使用资源。进程对资源进行操作，如用打印机进行打印。 
    + ③ 释放资源。当进程使用完自己释放资源。

+ 系统中每一类可重用性资源中的单元数目是相对固定的，进程在运行期间既不能创建也不能删除它。


对资源的请求和释放通常都是利用系统调用来实现的。

##### 5.1.1.2. 可消耗性资源

可消耗性资源又称为临时性资源，它是在进程运行期间，由进程动态地创建和消耗的。通常是由生产者进程创建，由消费者进程消耗。最典型的可消耗性资源就是用于进程间通信的消息等。

##### 5.1.1.3. 可抢占性资源

是指某进程在获得这类资源后，该资源可以再被其他进程或系统抢占。例如优先级高的进程可以抢占优先级低的进程的处理机。又如可以把一个进程从一个存储区转移到另一个存储区，在内存紧张时，还可将一个进程从内存调出到外存上，即抢占该进程在内存的空间。可见，CPU和主存均属于可抢占性资源。对于这类资源是不会引起死锁的。

##### 5.1.1.4. 不可抢占性资源

另一类资源是不可抢占性资源，即一旦系统把某资源分配给该进程后，就不能将它强行收回，只能在进程用完后自行释放。磁带机、打印机等就属于不可抢占性资源。

#### 5.1.2. 死锁的定义


死锁的起因，通常是源于多个进程对资源的争夺，不仅对不可抢占资源进行争夺时会引起死锁，而且对可消耗资源进行争夺时，也会引起死锁。

**在并发环境下，各进程因竞争资源而造成的一种互相等待对方手里的资源，导致各进程都阻塞，都无法向前推进的现象，就是“死锁”。**发生死锁后若无外力干涉，这些进程都将无法向前推进。即每个进程都占有一个资源，同时又在等待另一个进程手里的资源。就会发生“死锁”。

例如，在哲学家进餐问题中，如果每一个哲学家因饥饿都拿起了他们左边的筷子，当每一个哲学家又试图去拿起他们右边的筷子时，将会因无筷子可拿而无限期地等待，所以就出现了“死锁”的问题。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201531357.png" alt="image-20230720153120221" style="zoom: 67%;" />


#### 5.1.3. 死锁、饥饿、死循环的区别


死锁：各进程互相等待对方手里的资源，导致各进程都阻塞，无法向前推进的现象。 饥饿：由于长期得不到想要的资源，某进程无法向前推进的现象。比如：在短进程优先（SPF）算法中，若有源源不断的短进程到来，则长进程将一直得不到处理机，从而发生长进程“饥饿”。 死循环：某进程执行过程中一直跳不出某个循环的现象。有时是因为程序逻辑 bug 导致的，有时是程序员故意设计的。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306012320829.png" alt="image-20230601232026699" style="zoom: 67%;" />


#### 5.1.4. 死锁产生的原因


##### 5.1.4.1. 系统资源的竞争

各进程对不可剥夺的资源（如打印机）的竞争可能引起死锁，对可剥夺的资源（CPU）的竞争是不会引起死锁的。

##### 5.1.4.2. 进程推进顺序非法

进程推进顺序非法。请求和释放资源的顺序不当，也同样会导致死锁。例如，并发执行的进程P1、P2 分别申请并占有了资源 R1、R2，之后进程P1又紧接着申请资源R2，而进程P2又申请资源R1，两者会因为申请的资源被对方占有而阻塞，从而发生死锁。

##### 5.1.4.3. 信号量使用不当

信号量的使用不当也会造成死锁。如生产者-消费者问题中，如果实现互斥的P操作在实现同步的 P操作之前，就有可能导致死锁。（可以把互斥信号量、同步信号量也看做是一种抽象的系统资 源）

总之，对不可剥夺资源的不合理分配，可能导致死锁。产生死锁的原因包括资源竞争使用（某类资源数量不够）、进程间推进顺序不当。

#### 5.1.4.4. 死锁产生的必要条件

产生死锁必须同时满足一下四个条件，只要其中任一条件不成立，死锁就不会发生。


+ **互斥条件**：只有对必须互斥使用的资源的争抢才会导致死锁（如哲学家的筷子、打印机设备）。像内存、扬声器这样可以同时让多个进程使用的资源是不会导致死锁的（因为进程不用阻塞等待这种资源）。
+ **不剥夺条件**：进程所获得的资源在未使用完之前，不能由其他进程强行夺走，只能主动释放。
+ **请求和保持条件**：进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又被其他进程占有，此时请求进程被阻塞，但又对自己已有的资源保持不放。
+ **循环等待条件**：存在一种进程资源的循环等待链，链中的每一个进程已获得的资源同时被下一个进程所请求。（注意！发生死锁时一定有循环等待，但是发生循环等待时未必死锁（循环等待是死锁的必要不充分条件）） 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201531835.png" alt=".*?" style="zoom:50%;" />

如果同类资源数大于1，则即使有循环等待，也未必发生死锁。但如果系统中每类资源都只有一个，那循环等待就是死锁的充分必要条件了。 

-   当原本的五个哲学家都同时拿起左边的筷子时就进入了循环等待现象，而此时出现了第六个人，就可以破坏这种循环等待的现象，即当第六个人放下了自己手中的筷子时，3号哲学家就可以顺利进餐。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307201533184.png" alt="image-20230720153327039" style="zoom: 67%;" />


### 5.2. 死锁的处理策略


为使系统不发生死锁，必须设法破坏产生死锁的四个必要条件之一，或允许死锁产生，但当死锁发生时能检测出死锁，并有能力实现恢复。


+  **死锁预防** 设置某些限制条件，破坏产生死锁的4个必要条件中的一个或几个，以防止产生死锁。 
+  **避免死锁** 用某种方法防止系统进入不安全状态，从而避免死锁（银行家算法）。 
+  **死锁的检测及解除** 允许死锁的发生，不过操作系统会负责检测出死锁的发生，然后采取某种措施解除死锁。 


预防死锁和避免死锁都属于事先预防都属于事先预防策略，预防死锁的限制条件比较严格，实现起来较为简单，但往往导致系统的效率低，资源利用率低；避免死锁的限制条件相对宽松，资源分配后需要通过算法来判断是否进入不安全状态，实现起来较为复杂。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202235481.png" alt="image-20230720223508355" style="zoom: 67%;" />


### 5.3. 死锁预防

防止死锁的发生只需破坏死锁产生的4个必要条件之一即可。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306012338004.png" alt="image-20230601233841900" style="zoom: 67%;" />

#### 5.3.1. 破坏互斥条件


如果把只能互斥使用的资源改造为允许共享使用，则系统不会进入死锁状态。比如: SPOOLing技术。操作系统可以采用 SPOOLing 技术把独占设备在逻辑上改造成共享设备。比如，用SPOOLing技术将打印机改造为共享设备… 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202235533.png" alt=".*?" style="zoom: 50%;" />


 该策略的**缺点**：并不是所有的资源都可以改造成可共享使用的资源。并且为了系统安全，很多地方还必须保护这种互斥性。因此，很多时候都无法破坏互斥条件。

#### 5.3.2. 破坏不剥夺条件


方案一：当某个进程请求新的资源得不到满足时，它必须立即释放保持的所有资源，待以后需要时再重新申请。也就是说，即使某些资源尚未使用完，也需要主动释放，从而破坏了不可剥夺条件。

方案二：当某个进程需要的资源被其他进程所占有的时候，可以由操作系统协助，将想要的资源强行剥夺。这种方式一般需要考虑各进程的优先级（比如：剥夺调度方式，就是将处理机资源强行剥夺给优先级更高的进程使用）

该策略的**缺点**：


+ 实现起来比较复杂。
+ 释放已获得的资源可能造成前一阶段工作的失效。因此这种方法一般只适用于易保存和恢复状态的资源，如CPU。
+ 反复地申请和释放资源会增加系统开销，降低系统吞吐量。
+ 若采用方案一，意味着只要暂时得不到某个资源，之前获得的那些资源就都需要放弃，以后再重新申请。如果一直发生这样的情况，就会导致进程饥饿。


#### 5.3.3. 破坏请求和保持条件


可以采用静态分配方法，即进程在运行前一次申请完它所需要的全部资源，在它的资源未满足前，不让它投入运行。一旦投入运行后，这些资源就一直归它所有，该进程就不会再请求别的任何资源了。

该策略实现起来简单，但也有明显的**缺点**： 有些资源可能只需要用很短的时间，因此如果进程的整个运行期间都一直保持着所有资源，就会造成严重的资源浪费，资源利用率极低。另外，该策略也有可能导致某些进程饥饿。 

<img src="./figures\2500044eb4fd462fb972aca57cba904f.png" alt=".*?" style="zoom:50%;" />


#### 5.3.4. 破坏循环等待条件


可采用顺序资源分配法。首先给系统中的资源编号，规定每个进程必须按编号递增的顺序请求资源，同类资源（即编号相同的资源）一次申请完。

原理分析：一个进程只有已占有小编号的资源时，才有资格申请更大编号的资源。按此规则，已持有大编号资源的进程不可能逆向地回来申请小编号的资源（除非先释放所有具有相同和更高序号的资源后，才能申请序号低的资源），从而就不会产生循环等待的现象。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202236921.png" alt="image-20230720223648829" style="zoom: 67%;" />


该策略的**缺点**：


+ 不方便增加新的设备，因为可能需要重新分配所有的编号；
+ 进程实际使用资源的顺序可能和编号递增顺序不一致，会导致资源浪费；
+ 必须按规定次序申请资源，用户编程麻烦。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202237155.png" alt=".*?" style="zoom:50%;" />


### 5.4. 死锁避免


避免死锁同样属于事先预防策略，但并不是事先采取某种限制措施破坏死锁的必要条件，而是在资源动态分配过程中，防止系统进入不安全状态，以避免发生死锁。这种方式所施加的限制条件较弱，可以获得较好的系统性能。

#### 5.4.1. 系统安全状态

>   假如你是一位成功的银行家，手里掌握着100个亿的资金… 有三个企业想找你贷款，分别是 企业B、企业A、企业T，为描述方便，简称BAT。 B 表示：“大哥，我最多会跟你借70亿…” A 表示：“大哥，我最多会跟你借40亿…” T 表示：“大哥，我最多会跟你借50亿…” **然而…江湖中有个不成文的规矩：如果你借给企业的钱总数达不到企业提出的最大要求，那么不管你之前给企业借了多少钱，那些钱都拿不回来了…** 刚开始，BAT三个企业分别从你这儿借了 20、10、30 亿 … 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202238057.png" alt=".*?" style="zoom: 50%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202239204.png" alt="image-20230720223919132" style="zoom:67%;" />

>   所以A借20亿后，还是安全的，然后所形成的顺序被我们称为安全队列。 但若是B想借30亿的话则是不安全的。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202239395.png" alt="image-20230720223936267" style="zoom: 67%;" />

所谓安全序列，就是指如果系统按照这种序列分配资源，则每个进程都能顺利完成。只要能找出一个安全序列，系统就是安全状态。当然，安全序列可能有多个。

如果分配了资源之后，系统中找不出任何一个安全序列，系统就进入了不安全状态。这就意味着之后可能所有进程都无法顺利的执行下去（死锁）。当然，如果有进程提前归还了一些资源（比如A 先归还了10亿，那么就有安全序列T→B→A），那系统也有可能重新回到安全状态，不过我们在分配资源之前总是要考虑到最坏的情况。

如果系统处于安全状态，就一定不会发生死锁。如果系统进入不安全状态，就可能发生死锁（处于不安全状态未必就是发生了死锁，但发生死锁时一定是在不安全状态）

因此可以在资源分配之前预先判断这次分配是否会导致系统进入不安全状态，以此决定是否答应资源分配请求。这也是“银行家算法”的核心思想。

#### 5.4.2. 银行家算法

>   银行家算法是荷兰学者 Dijkstra 为银行系统设计的，以确保银行在发放现金贷款时，不会发生不能满足所有客户需要的情况。后来该算法被用在操作系统中，用于避免死锁。

**核心思想**：在进程提出资源申请时，先预判此次分配是否会导致系统进入不安全状态。如果会进入不安全状态，就暂时不答应这次请求，让该进程先阻塞等待。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202240952.png" alt=".*?" style="zoom:50%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202241065.png" alt="image-20230720224145941" style="zoom: 67%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202243265.png" alt="image-20230720224308046" style="zoom: 67%;" />

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202243946.png" alt="image-20230720224354856" style="zoom:67%;" />


 可满足P1需求，将 P1 加入安全序列，并更新剩余可用资源值为 (5, 3, 2) 依次检查剩余可用资源 (5, 3, 2) 是否能满足剩余进程（不包括已加入安全序列的进程）的需求 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202244058.png" alt="image-20230720224437964" style="zoom:67%;" />


 可满足P3需求，将 P3 加入安全序列，并更新剩余可用资源值为 (7, 4, 3) 此时安全序列为：P1 → P3 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202244774.png" alt="image-20230720224458623" style="zoom:67%;" />

 依次检查剩余可用资源 (7, 4, 3) 是否能满足剩余进程（不包括已加入安全序列的进程）的需求…… …… 以此类推，共五次循环检查即可将5个进程都加入安全序列中，最终可得一个安全序列（P1 → P3 → P0 → P2 → P4）。该算法称为安全性算法。可以很方便地用代码实现以上流程，每一轮检查都从编号较小的进程开始检查。实际做题时可以更快速的得到安全序列。

-   **实际做题（手算）时可用更快速的方法找到一个安全序列**： 经对比发现，（3, 3, 2）可满足 P1、P3，说明无论如何，这两个进程的资源需求一定是可以依次被满足的，因此P1、P3 一定可以顺利的执行完，并归还资源。 可把 P1、P3 先加入安全序列。 (2, 0, 0)+ (2, 1, 1)+ (3, 3, 2) = (7, 4, 3) 剩下的 P0、P2、P4 都可被满足。同理，这些进程都可以加入安全序列。 于是，5个进程全部加入安全序列，说明此时系统处于安全状态，暂不可能发生死锁。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202245788.png" alt=".*?" style="zoom: 50%;" />

##### 5.4.2.1. 银行家算法的数据结构

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202246783.png" alt="image-20230720224619704" style="zoom:67%;" />


 假设系统中有 n 个进程，m 种资源。 每个进程在运行前先声明对各种资源的最大需求数，则可用一个 n * m 的矩阵（可用二维数组实现）表示所有进程对各种资源的最大需求数。不妨称为最大需求矩阵 Max，Max[i, j]=K 表示进程 Pi 最多需要 K 个资源 Rj。同理，系统可以用一个 n*m 的分配矩阵Allocation表示对所有进程的资源分配情况。Max – Allocation = Need 矩阵，表示各进程最多还需要多少各类资源。 另外，还要用一个长度为m的一维数组 Available 表示当前系统中还有多少可用资源。某进程 Pi 向系统申请资源，可用一个长度为m的 一维数组 Requesti 表示本次申请的各种资源量。

##### 5.4.2.2. 银行家算法的描述

设Requesti 是进程Pi 的请求向量，如果Requesti[j]=K，表示进程Pi需要K个Rj类型的资源。当Pi发出资源请求后，系统按下述步骤进行检查：


+ 如果 Requesti[j]≤Need[i, j] (0≤j≤m)便转向第二步；否则认为出错。 （因为它所需要的资源数已超过它所宣布的最大值。）
+ 如果 Requesti[j]≤Available[j] (0≤j≤m)，便转向第三步 ；否则表示尚无足够资源，Pi必须等待。
+ 系统试探着把资源分配给进程Pi，并修改相应的数据（并非真的分配，修改数值只是为了做预判）： Available = Available - Requesti; Allocation[i, j] = Allocation[i, j] 
+ Requesti[j]; Need[i, j] = Need[i, j] – Requesti[j]
+ 操作系统执行安全性算法，检查此次资源分配后，系统是否处于安全状态。若安全，才正式分配；否则，恢复相应数据，让进程阻塞等待。


##### 5.4.2.3. 安全性算法

简言之就是，检查当前的剩余可用资源是否能满足某个进程的最大需求，如果可以，就把该进程加入安全序列，**并把该进程持有的资源全部回收。** 不断重复上述过程，看最终是否能让所有进程都加入安全序列。其实，具体步骤上面例子已经有展示了。

最后，提醒一下，**系统处于不安全状态未必死锁，但死锁时一定处于不安全状态**。系统处于安全状态一定不会死锁。

### 5.5. 死锁检测和解除

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306020020901.png" alt="image-20230602002024802" style="zoom:50%;" />

 如果系统中既不采取预防死锁的措施，也不采取避免死锁的措施，系统就很可能发生死锁。在这种情况下，系统应当提供两个算法： 

-   ①**死锁检测算法**：用于检测系统状态，以确定系统中是否发生了死锁。 
-   ②**死锁解除算法**：当认定系统中已经发生了死锁，利用该算法可将系统从死锁状态中解脱出来。

#### 5.5.1. 死锁检测

为了能对系统是否已发生了死锁进行检测，必须： 

-   ①用某种数据结构来保存资源的请求和分配信息；
-    ②提供一种算法，利用上述信息来检测系统是否已进入死锁状态。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202246232.png" alt=".*?" style="zoom: 80%;" />


 如果系统中剩余的可用资源数足够满足进程的需求，那么这个进程暂时是不会阻塞的，可以顺利地执行下去。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202247963.png" alt=".*?" style="zoom:67%;" />


如果这个进程执行结束了把资源归还系统，就可能使某些正在等待资源的进程被激活，并顺利地执行下去。相应的，这些被激活的进程执行完了之后又会归还一些资源，这样可能又会激活另外一些阻塞的进程… 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202247557.png" alt=".*?"  />


 如果按上述过程分析，最终能消除所有边，就称这个图是可完全简的。此时一定没有发生死锁（相当于能找到一个安全序列）。

如果最终不能消除所有边，那么此时就是发生了死锁。 

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202307202247202.png" alt=".*?" style="zoom:80%;" />


 最终还连着边的那些进程（P1和P2）就是处于死锁状态的进程。

**检测死锁的算法：** 

+   （1）在资源分配图中，找出既不阻塞又不是孤点的进程 Pi（即找出一条有向边与它相连，且该有向边对应资源的申请数量小于等于系统中已有空闲资源数量。如下图中，R1没有空闲资源，R2有一个空闲资源。若所有的连接该进程的边均满足上述条件，则这个进程能继续运行直至完成，然后释放它所占有的所有资源）。消去它所有的请求边和分配变，使之称为孤立的结点。在下图中，P1 是满足这一条件的进程结点，于是将P1的所有边消去。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306020027624.png" alt="image-20230602002705556" style="zoom: 67%;" />

-   （2）进程 Pi 所释放的资源，可以唤醒某些因等待这些资源而阻塞的进程，原来的阻塞进程可能变为非阻塞进程。在下图中，P2 就满足这样的条件。根据（1）中的方法进行一系列简化后，若能消去途中所有的边，则称该图是可完全简化的。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306020028514.png" alt="image-20230602002808447" style="zoom:67%;" />

检测死锁其实就是依次消除与不阻塞相连的边，直到无边可销。

-   **死锁定理**：如果某时刻系统的**资源分配图**是**不可完全简化的，那么此时系统死锁。**

#### 5.5.2. 死锁解除


一旦检测出死锁的发生，就应该立即解除死锁。 补充：并不是系统中所有的进程都是死锁状态，用死锁检测算法化简资源分配图后，还连着边的那些进程就是死锁进程。

解除死锁的主要方法有：


+ **资源剥夺法**。挂起（暂时放到外存上）某些死锁进程，并抢占它的资源，将这些资源分配给其他的死锁进程。但是应防止被挂起的进程长时间得不到资源而饥饿。
+ **撤销进程法**（或称终止进程法）。强制撤销部分、甚至全部死锁进程，并剥夺这些进程的资源。这种方式的优点是实现简单，但所付出的代价可能会很大。因为有些进程可能已经运行了很长时间，已经接近结束了，一旦被终止可谓功亏一篑，以后还得从头再来。
+ **进程回退法**。让一个或多个死锁进程回退到足以避免死锁的地步。这就要求系统要记录进程的历史信息，设置还原点。


终止进程时应考虑的因素：


+ 进程的优先级的大小；
+ 进程已执行了多少时间，还需要多少时间才能完成
+ 进程在运行中已经使用多少资源，以后还需多少资源；
+ 进程的性质是交互式的还是**批处理式**【先】的。

<img src="https://cdn.jsdelivr.net/gh/ZeirSor/picgo_img@main/202306020032825.png" alt="image-20230602003232733" style="zoom: 67%;" />


### 5.6. 补充

+ 死锁一定要有两个或两个以上的进程才会导致，而饥饿可能由一个进程导致。
+ 一次分配所有资源的方法是破坏死锁的四个必要条件中的请求和保持条件。
+ 系统死锁的可能原因主要是时间上和空间上的。时间上由于进程运行中推进顺序不当，即调用时间不合适，不该切换进程时进行了切换，可能会造成死锁。空间上的原因是对独占资源分配不当，互斥资源部分分配又不可剥夺，极易造成死锁。 系统资源不足不是造成死锁的原因。
+ 引入多道程序技术的前提条件之一是系统具有中断功能。多道程序技术要求进程间实现并发，而并发性的实现需要中断功能的支持。
+ 死锁的四个必要条件中，无法破坏的是互斥使用资源。所谓破坏互斥使用资源，是指允许多个进程同时访问资源，但有些资源根本不能同时访问，如打印机只能互斥使用。因此破坏互斥条件而预防死锁的方法不太可行。而且有的场合还应保护这种互斥性。
+ 系统的资源分配图中，如出现了环路是无法判断是否处于死锁状态的。出现了，只是满足了循环等待的必要条件，而满足必要条件不一定会导致死锁。要是每种资源只有一个且出现了环路，就一定会发生死锁。
+ 产生死锁的根本原因是系统资源分配不足和进程推进顺序非法。
+ 死锁定理是用于检测死锁的方法。
+ 死锁在系统中不可能完全消灭，但我们要尽可能地减少死锁的发生。对死锁的处理有4种方法：忽略、检测和解除、避免与预防，每种方法对死锁的处理从宽到严，同时系统并发性由大到小。
